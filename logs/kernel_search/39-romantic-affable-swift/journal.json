{"nodes":[{"code":"import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# CUDA kernel source for tiled matrix multiplication\ncuda_source = \"\"\"\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n\n// Tiled matrix multiplication kernel\n// C = A * B\n__global__ void matmul_tiled_kernel(const float* A, const float* B, float* C, int N) {\n    // Block and thread indices\n    int blockRow = blockIdx.y;\n    int blockCol = blockIdx.x;\n    int row = threadIdx.y;\n    int col = threadIdx.x;\n\n    // TILE_SIZE must match blockDim.x and blockDim.y\n    const int TILE_SIZE = 32; \n\n    // Global row and column of the C element computed by this thread\n    int C_row = blockRow * TILE_SIZE + row;\n    int C_col = blockCol * TILE_SIZE + col;\n\n    float C_value = 0.0f; // Accumulator for the C element\n\n    // Shared memory for tiles of A and B\n    __shared__ float As[TILE_SIZE][TILE_SIZE];\n    __shared__ float Bs[TILE_SIZE][TILE_SIZE];\n\n    // Loop over the K dimension (inner product)\n    // Each iteration processes one \"sub-tile\" multiplication\n    for (int tile_idx = 0; tile_idx < (N + TILE_SIZE - 1) / TILE_SIZE; ++tile_idx) {\n        // Load tiles from global memory to shared memory\n        // Each thread loads one element into As and one into Bs\n        int A_global_row = blockRow * TILE_SIZE + row;\n        int A_global_col = tile_idx * TILE_SIZE + col;\n        int B_global_row = tile_idx * TILE_SIZE + row;\n        int B_global_col = blockCol * TILE_SIZE + col;\n\n        // Load element for As\n        if (A_global_row < N && A_global_col < N) {\n            As[row][col] = A[A_global_row * N + A_global_col];\n        } else {\n            As[row][col] = 0.0f; // Pad with zeros if out of bounds\n        }\n\n        // Load element for Bs\n        if (B_global_row < N && B_global_col < N) {\n            Bs[row][col] = B[B_global_row * N + B_global_col];\n        } else {\n            Bs[row][col] = 0.0f; // Pad with zeros if out of bounds\n        }\n\n        __syncthreads(); // Wait for all threads in the block to load their tile\n\n        // Perform dot product using shared memory tiles\n        // Each thread computes one element of C_value for the current sub-tile\n        for (int k = 0; k < TILE_SIZE; ++k) {\n            C_value += As[row][k] * Bs[k][col];\n        }\n\n        __syncthreads(); // Wait for all threads to finish computation for this sub-tile\n    }\n\n    // Write the accumulated result to global memory\n    if (C_row < N && C_col < N) {\n        C[C_row * N + C_col] = C_value;\n    }\n}\n\n// C++ wrapper function to launch the CUDA kernel\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    // Input validation\n    TORCH_CHECK(A.is_cuda() && B.is_cuda(), \"Inputs must be CUDA tensors.\");\n    TORCH_CHECK(A.is_contiguous() && B.is_contiguous(), \"Inputs must be contiguous.\");\n    TORCH_CHECK(A.dtype() == torch::kFloat && B.dtype() == torch::kFloat, \"Inputs must be float32.\");\n    \n    int N = A.size(0);\n    TORCH_CHECK(A.size(1) == N && B.size(0) == N && B.size(1) == N, \n                \"Inputs must be square matrices of the same size.\");\n\n    // Create output tensor on the same device and with the same dtype as inputs\n    auto C = torch::zeros({N, N}, A.options());\n\n    // Kernel launch configuration\n    const int TILE_SIZE = 32; // This must match the TILE_SIZE in the kernel\n    dim3 block_dim(TILE_SIZE, TILE_SIZE); // 2D block for 2D matrix operations\n    dim3 grid_dim((N + TILE_SIZE - 1) / TILE_SIZE, (N + TILE_SIZE - 1) / TILE_SIZE); // 2D grid\n\n    // Launch the kernel\n    matmul_tiled_kernel<<<grid_dim, block_dim>>>(\n        A.data_ptr<float>(),\n        B.data_ptr<float>(),\n        C.data_ptr<float>(),\n        N\n    );\n\n    return C;\n}\n\"\"\"\n\n# C++ function declaration for load_inline\ncpp_source = \"torch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B);\"\n\n# Compile the inline CUDA code\n# The name 'matmul_custom_extension' should be unique\n_matmul_custom = load_inline(\n    name=\"matmul_custom_extension\",\n    cpp_sources=cpp_source,\n    cuda_sources=cuda_source,\n    functions=[\"matmul_cuda\"],  # The C++ function name to expose\n    verbose=True,\n)\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model that performs a single square matrix multiplication (C = A * B)\n    using a custom tiled CUDA kernel.\n    \"\"\"\n\n    def __init__(self):\n        super(ModelNew, self).__init__()\n        # Store the compiled CUDA function\n        self.matmul_op = _matmul_custom.matmul_cuda\n\n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the matrix multiplication using the custom CUDA kernel.\n\n        Args:\n            A (torch.Tensor): Input matrix A of shape (N, N).\n            B (torch.Tensor): Input matrix B of shape (N, N).\n\n        Returns:\n            torch.Tensor: Output matrix C of shape (N, N).\n        \"\"\"\n        return self.matmul_op(A, B)\n","plan":"A common strategy for optimizing matrix multiplication on GPUs is to use tiled matrix multiplication. This approach divides the matrices into smaller tiles that can be loaded into faster shared memory, reducing global memory access and improving data reuse. My plan is to implement a basic tiled matrix multiplication kernel that leverages shared memory to store sub-matrices of A and B for each thread block. Each thread block will compute a tile of the output matrix C by iterating through the K-dimension, loading corresponding tiles of A and B into shared memory, performing the dot product, and accumulating the result.","step":0,"id":"3932fd97b9b0423e9153c3435b32e69f","ctime":1762746534.3484297,"parent":null,"children":[],"_term_out":["================================================================================","KERNEL EVALUATION SUCCESS","================================================================================","\u2713 Compilation: PASSED","\u2713 Correctness: PASSED","  Correctness trials: (5 / 5)","\n\u2713 Performance: 37.700 ms","  Mean: 37.700 ms","  Std:  0.278 ms","  Min:  37.600 ms","  Max:  40.200 ms","  Trials: 100","\nHardware: NVIDIA TITAN V","Runtime: 0.038 seconds"],"exec_time":0.037700000000000004,"exc_type":null,"exc_info":null,"exc_stack":null,"analysis":"Kernel implementation successful! Runtime: 37.700 ms. The kernel compiled correctly, passed all correctness checks, and was successfully profiled.","metric":{"value":37.7,"maximize":false},"is_buggy":false}],"node2parent":{},"__version":"2"}