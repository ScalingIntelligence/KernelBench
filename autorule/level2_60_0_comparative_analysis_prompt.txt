You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 29.0 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for fused Swish + GroupNorm + HardSwish
fused_kernel_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void fused_swish_groupnorm_hardswish_kernel(
    const float* input,
    const float* gamma,
    const float* beta,
    float* output,
    int N, int C, int D, int H, int W, int G,
    int group_size,
    float eps) {
    
    int n = blockIdx.x;
    int g = blockIdx.y;
    int tid = threadIdx.x;
    
    int c_start = g * group_size;
    int num_elements = group_size * D * H * W;
    
    extern __shared__ float smem[];
    float* sum = smem;
    float* sum_sq = &smem[blockDim.x];
    
    // First pass: compute sum and sum_sq with strided access
    float local_sum = 0.0f;
    float local_sum_sq = 0.0f;
    for(int i = tid; i < num_elements; i += blockDim.x) {
        int c = c_start + i / (D * H * W);
        int spatial_idx = i % (D * H * W);
        int d = spatial_idx / (H * W);
        int h = (spatial_idx % (H * W)) / W;
        int w = spatial_idx % W;
        
        int idx = n * C * D * H * W + c * D * H * W + d * H * W + h * W + w;
        float x = input[idx];
        float swish_x = x * (1.0f / (1.0f + __expf(-x)));
        local_sum += swish_x;
        local_sum_sq += swish_x * swish_x;
    }
    
    sum[tid] = local_sum;
    sum_sq[tid] = local_sum_sq;
    __syncthreads();
    
    // Block reduction for sum and sum_sq
    for(int s = blockDim.x/2; s > 0; s >>= 1) {
        if(tid < s) {
            sum[tid] += sum[tid + s];
            sum_sq[tid] += sum_sq[tid + s];
        }
        __syncthreads();
    }
    
    float total_sum = sum[0];
    float total_sum_sq = sum_sq[0];
    float mean = total_sum / num_elements;
    float var = (total_sum_sq / num_elements) - (mean * mean);
    float inv_std = rsqrtf(var + eps);
    
    // Second pass: apply normalization and activations
    for(int i = tid; i < num_elements; i += blockDim.x) {
        int c = c_start + i / (D * H * W);
        int spatial_idx = i % (D * H * W);
        int d = spatial_idx / (H * W);
        int h = (spatial_idx % (H * W)) / W;
        int w = spatial_idx % W;
        
        int idx = n * C * D * H * W + c * D * H * W + d * H * W + h * W + w;
        float x = input[idx];
        float swish_x = x * (1.0f / (1.0f + __expf(-x)));
        
        float normalized = (swish_x - mean) * inv_std * gamma[c] + beta[c];
        float hardswish = normalized * fminf(fmaxf(normalized + 3.0f, 0.0f), 6.0f) / 6.0f;
        output[idx] = hardswish;
    }
}

torch::Tensor fused_swish_groupnorm_hardswish_cuda(
    torch::Tensor input,
    torch::Tensor gamma,
    torch::Tensor beta,
    int groups,
    float eps) {
    
    auto N = input.size(0);
    auto C = input.size(1);
    auto D = input.size(2);
    auto H = input.size(3);
    auto W = input.size(4);
    int group_size = C / groups;
    
    auto output = torch::empty_like(input);
    
    dim3 grid(N, groups);
    int block = 256;
    size_t shared_mem = 2 * block * sizeof(float);
    
    fused_swish_groupnorm_hardswish_kernel<<<grid, block, shared_mem>>>(
        input.data_ptr<float>(),
        gamma.data_ptr<float>(),
        beta.data_ptr<float>(),
        output.data_ptr<float>(),
        N, C, D, H, W, groups,
        group_size,
        eps);
    
    return output;
}
"""

fused_kernel_cpp_source = """
torch::Tensor fused_swish_groupnorm_hardswish_cuda(torch::Tensor input, torch::Tensor gamma, torch::Tensor beta, int groups, float eps);
"""

# Compile CUDA extension
fused_ops = load_inline(
    name="fused_ops",
    cpp_sources=fused_kernel_cpp_source,
    cuda_sources=fused_kernel_source,
    functions=["fused_swish_groupnorm_hardswish_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[],
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size, 
            stride=stride, padding=padding, bias=bias
        )
        self.groups = groups
        self.eps = eps
        self.gamma = nn.Parameter(torch.ones(out_channels))
        self.beta = nn.Parameter(torch.zeros(out_channels))
        
        if out_channels % groups != 0:
            raise ValueError("out_channels must be divisible by groups")

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_ops.fused_swish_groupnorm_hardswish_cuda(
            x, self.gamma, self.beta, self.groups, self.eps
        )
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width).cuda()]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]
```

Kernel 2 (runtime: 28.9 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for fused Swish + GroupNorm + HardSwish
fused_kernel_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void fused_swish_groupnorm_hardswish_kernel(
    const float* input,
    const float* gamma,
    const float* beta,
    float* output,
    int N, int C, int D, int H, int W, int G,
    int group_size,
    float eps) {
    
    int n = blockIdx.x;
    int g = blockIdx.y;
    int tid = threadIdx.x;
    
    int c_start = g * group_size;
    int c_end = c_start + group_size;
    int num_elements = group_size * D * H * W;
    
    extern __shared__ float smem[];
    float* sum = smem;
    float* sum_sq = &smem[blockDim.x];
    
    // First pass: compute sum and sum_sq
    float local_sum = 0.0f;
    float local_sum_sq = 0.0f;
    for(int i = tid; i < num_elements; i += blockDim.x) {
        int c = c_start + i / (D * H * W);
        int spatial_idx = i % (D * H * W);
        int d = spatial_idx / (H * W);
        int h = (spatial_idx % (H * W)) / W;
        int w = spatial_idx % W;
        
        int idx = n * C * D * H * W + c * D * H * W + d * H * W + h * W + w;
        float x = input[idx];
        float swish_x = x * (1.0f / (1.0f + expf(-x)));
        local_sum += swish_x;
        local_sum_sq += swish_x * swish_x;
    }
    
    sum[tid] = local_sum;
    sum_sq[tid] = local_sum_sq;
    __syncthreads();
    
    // Block reduction for sum and sum_sq
    for(int s = blockDim.x/2; s > 0; s >>= 1) {
        if(tid < s) {
            sum[tid] += sum[tid + s];
            sum_sq[tid] += sum_sq[tid + s];
        }
        __syncthreads();
    }
    
    float total_sum = sum[0];
    float total_sum_sq = sum_sq[0];
    float mean = total_sum / num_elements;
    float var = (total_sum_sq / num_elements) - (mean * mean);
    float inv_std = rsqrtf(var + eps);
    
    // Second pass: apply normalization and activations
    for(int i = tid; i < num_elements; i += blockDim.x) {
        int c = c_start + i / (D * H * W);
        int spatial_idx = i % (D * H * W);
        int d = spatial_idx / (H * W);
        int h = (spatial_idx % (H * W)) / W;
        int w = spatial_idx % W;
        
        int idx = n * C * D * H * W + c * D * H * W + d * H * W + h * W + w;
        float x = input[idx];
        float swish_x = x * (1.0f / (1.0f + expf(-x)));
        
        float normalized = (swish_x - mean) * inv_std * gamma[c] + beta[c];
        float hardswish = normalized * fminf(fmaxf(normalized + 3.0f, 0.0f), 6.0f) / 6.0f;
        output[idx] = hardswish;
    }
}

torch::Tensor fused_swish_groupnorm_hardswish_cuda(
    torch::Tensor input,
    torch::Tensor gamma,
    torch::Tensor beta,
    int groups,
    float eps) {
    
    auto N = input.size(0);
    auto C = input.size(1);
    auto D = input.size(2);
    auto H = input.size(3);
    auto W = input.size(4);
    int group_size = C / groups;
    
    auto output = torch::empty_like(input);
    
    dim3 grid(N, groups);
    int block = 256;
    size_t shared_mem = 2 * block * sizeof(float);
    
    fused_swish_groupnorm_hardswish_kernel<<<grid, block, shared_mem>>>(
        input.data_ptr<float>(),
        gamma.data_ptr<float>(),
        beta.data_ptr<float>(),
        output.data_ptr<float>(),
        N, C, D, H, W, groups,
        group_size,
        eps);
    
    return output;
}
"""

fused_kernel_cpp_source = """
torch::Tensor fused_swish_groupnorm_hardswish_cuda(torch::Tensor input, torch::Tensor gamma, torch::Tensor beta, int groups, float eps);
"""

# Compile CUDA extension
fused_ops = load_inline(
    name="fused_ops",
    cpp_sources=fused_kernel_cpp_source,
    cuda_sources=fused_kernel_source,
    functions=["fused_swish_groupnorm_hardswish_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[],
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size, 
            stride=stride, padding=padding, bias=bias
        )
        self.groups = groups
        self.eps = eps
        self.gamma = nn.Parameter(torch.ones(out_channels))
        self.beta = nn.Parameter(torch.zeros(out_channels))
        
        # Validate group parameters
        if out_channels % groups != 0:
            raise ValueError("out_channels must be divisible by groups")

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_ops.fused_swish_groupnorm_hardswish_cuda(
            x, self.gamma, self.beta, self.groups, self.eps
        )
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width).cuda()]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]
```
