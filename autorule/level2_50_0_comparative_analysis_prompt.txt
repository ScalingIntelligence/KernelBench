You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 23.2 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom fused kernel for AvgPool3d + scale1 + bias + scale2
fused_kernel_code = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void fused_avgpool_scale_bias_scale_kernel(
    const float* input,
    const float* bias,
    float scale1,
    float scale2,
    float* output,
    int N, int C, int D, int H, int W,
    int output_D, int output_H, int output_W
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_output_elements = N * C * output_D * output_H * output_W;
    if (idx >= total_output_elements) return;

    // Decompose idx into n, c, d, h, w
    int n = idx / (C * output_D * output_H * output_W);
    int remainder = idx % (C * output_D * output_H * output_W);
    int c = remainder / (output_D * output_H * output_W);
    remainder = remainder % (output_D * output_H * output_W);
    int d = remainder / (output_H * output_W);
    remainder = remainder % (output_H * output_W);
    int h = remainder / output_W;
    int w = remainder % output_W;

    // Input window starting indices
    int d_in_start = d * 2;
    int h_in_start = h * 2;
    int w_in_start = w * 2;

    float sum = 0.0f;
    int count = 0;
    for (int dd = 0; dd < 2; dd++) {
        for (int dh = 0; dh < 2; dh++) {
            for (int dw = 0; dw < 2; dw++) {
                int d_in = d_in_start + dd;
                int h_in = h_in_start + dh;
                int w_in = w_in_start + dw;
                if (d_in < D && h_in < H && w_in < W) {
                    int input_idx = n * C * D * H * W +
                                    c * D * H * W +
                                    d_in * H * W +
                                    h_in * W +
                                    w_in;
                    sum += input[input_idx];
                    count++;
                }
            }
        }
    }
    float avg = count > 0 ? sum / count : 0.0f;
    avg = avg * scale1 + bias[c];
    avg *= scale2;

    output[idx] = avg;
}

torch::Tensor fused_ops_cuda(
    torch::Tensor input,
    torch::Tensor bias,
    torch::Tensor scale1,
    torch::Tensor scale2
) {
    TORCH_CHECK(input.dim() == 5, "Input must be 5D (N, C, D, H, W)");
    int N = input.size(0);
    int C = input.size(1);
    int D = input.size(2);
    int H = input.size(3);
    int W = input.size(4);

    int output_D = D / 2;
    int output_H = H / 2;
    int output_W = W / 2;
    auto output = torch::empty({N, C, output_D, output_H, output_W}, input.options());

    int total_output_elements = N * C * output_D * output_H * output_W;
    const int block_size = 256;
    int grid_size = (total_output_elements + block_size - 1) / block_size;

    float scale1_val = scale1.item<float>();
    float scale2_val = scale2.item<float>();

    fused_avgpool_scale_bias_scale_kernel<<<grid_size, block_size>>>(
        input.data_ptr<float>(),
        bias.data_ptr<float>(),
        scale1_val,
        scale2_val,
        output.data_ptr<float>(),
        N, C, D, H, W,
        output_D, output_H, output_W
    );

    return output;
}
"""

fused_kernel_cpp = "torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor bias, torch::Tensor scale1, torch::Tensor scale2);"

fused_ops = load_inline(
    name='fused_ops',
    cpp_sources=fused_kernel_cpp,
    cuda_sources=fused_kernel_code,
    functions=['fused_ops_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size, stride, padding)
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.scale1 = nn.Parameter(torch.tensor(scale1))
        self.scale2 = nn.Parameter(torch.tensor(scale2))

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_ops.fused_ops_cuda(x, self.bias, self.scale1, self.scale2)
        return x
```

Kernel 2 (runtime: 23.0 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

fused_ops_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void fused_scale_pool_bias_scale_kernel(
    const float* input,
    const float scale1,
    const float* bias,
    const float scale2,
    float* output,
    int batch_size,
    int channels,
    int input_depth,
    int input_height,
    int input_width,
    int output_depth,
    int output_height,
    int output_width
) {
    int total_output_elements = batch_size * channels * output_depth * output_height * output_width;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx >= total_output_elements) return;

    // Decompose global index
    int remaining = idx;
    const int b = remaining / (channels * output_depth * output_height * output_width);
    remaining %= (channels * output_depth * output_height * output_width);
    const int c = remaining / (output_depth * output_height * output_width);
    remaining %= (output_depth * output_height * output_width);
    const int d = remaining / (output_height * output_width);
    remaining %= (output_height * output_width);
    const int h = remaining / output_width;
    const int w = remaining % output_width;

    // Input window coordinates
    const int input_d_start = d * 2;
    const int input_h_start = h * 2;
    const int input_w_start = w * 2;

    float sum = 0.0f;
    int valid_count = 0;

    // 2x2x2 pooling window
    for (int dd = 0; dd < 2; ++dd) {
        for (int hh = 0; hh < 2; ++hh) {
            for (int ww = 0; ww < 2; ++ww) {
                const int input_d = input_d_start + dd;
                const int input_h = input_h_start + hh;
                const int input_w = input_w_start + ww;

                if (input_d < input_depth && input_h < input_height && input_w < input_width) {
                    const int input_idx = b * channels * input_depth * input_height * input_width +
                                        c * input_depth * input_height * input_width +
                                        input_d * input_height * input_width +
                                        input_h * input_width +
                                        input_w;
                    sum += input[input_idx] * scale1;
                    valid_count++;
                }
            }
        }
    }

    // Average pooling with valid element count
    float avg = sum / valid_count;
    avg += bias[c];
    avg *= scale2;

    // Write output
    const int output_idx = b * channels * output_depth * output_height * output_width +
                          c * output_depth * output_height * output_width +
                          d * output_height * output_width +
                          h * output_width +
                          w;
    output[output_idx] = avg;
}

torch::Tensor fused_scale_pool_bias_scale_cuda(
    torch::Tensor input,
    torch::Tensor scale1,
    torch::Tensor bias,
    torch::Tensor scale2
) {
    // Validate input dimensions
    TORCH_CHECK(input.dim() == 5, "Input must be 5D tensor");
    
    const auto batch_size = input.size(0);
    const auto channels = input.size(1);
    const auto input_depth = input.size(2);
    const auto input_height = input.size(3);
    const auto input_width = input.size(4);

    // Calculate output dimensions
    const int output_depth = input_depth / 2;
    const int output_height = input_height / 2;
    const int output_width = input_width / 2;

    auto output = torch::empty({batch_size, channels, output_depth, output_height, output_width}, input.options());

    const int total_elements = batch_size * channels * output_depth * output_height * output_width;
    const int block_size = 256;
    const int num_blocks = (total_elements + block_size - 1) / block_size;

    fused_scale_pool_bias_scale_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        scale1.item<float>(),
        bias.data_ptr<float>(),
        scale2.item<float>(),
        output.data_ptr<float>(),
        batch_size,
        channels,
        input_depth,
        input_height,
        input_width,
        output_depth,
        output_height,
        output_width
    );

    return output;
}
"""

fused_ops_cpp_source = """
torch::Tensor fused_scale_pool_bias_scale_cuda(torch::Tensor input, torch::Tensor scale1, torch::Tensor bias, torch::Tensor scale2);
"""

fused_ops = load_inline(
    name='fused_ops',
    cpp_sources=fused_ops_cpp_source,
    cuda_sources=fused_ops_source,
    functions=['fused_scale_pool_bias_scale_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size, stride=stride, padding=padding
        )
        self.scale1 = nn.Parameter(torch.tensor(scale1))
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.scale2 = nn.Parameter(torch.tensor(scale2))

    def forward(self, x):
        x = self.conv_transpose(x.contiguous())
        x = fused_ops.fused_scale_pool_bias_scale_cuda(x, self.scale1, self.bias, self.scale2)
        return x
```
