You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 495.0 ms):
```
import torch
import torch.nn as nn
import math
from torch.utils.cpp_extension import load_inline

conv2d_cuda_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

using namespace torch;

__global__ void conv2d_forward_kernel(
    const float* __restrict__ input,
    const float* __restrict__ weight,
    const float* __restrict__ bias,
    float* __restrict__ output,
    const int batch_size,
    const int in_channels,
    const int out_channels,
    const int in_height,
    const int in_width,
    const int kernel_size,
    const int stride,
    const int padding,
    const int dilation,
    const int groups,
    const int out_height,
    const int out_width
) {
    const int total_elements = batch_size * out_channels * out_height * out_width;
    const int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= total_elements) return;

    // Decompose index into n, oc, oh, ow
    const int n = idx / (out_channels * out_height * out_width);
    int rem = idx % (out_channels * out_height * out_width);
    const int oc = rem / (out_height * out_width);
    rem = rem % (out_height * out_width);
    const int oh = rem / out_width;
    const int ow = rem % out_width;

    const int group_in_channels = in_channels / groups;
    const int g = oc / (out_channels / groups);

    float sum = 0.0f;

    for (int ic = 0; ic < group_in_channels; ++ic) {
        for (int ky = 0; ky < kernel_size; ++ky) {
            const int in_y = oh * stride + ky * dilation - padding;
            if (in_y < 0 || in_y >= in_height) continue;
            
            #pragma unroll
            for (int kx = 0; kx < kernel_size; ++kx) {
                const int in_x = ow * stride + kx * dilation - padding;
                if (in_x < 0 || in_x >= in_width) continue;

                const int input_idx = ((n * in_channels + (g * group_in_channels + ic)) * in_height + in_y) * in_width + in_x;
                const int weight_idx = ((oc * group_in_channels + ic) * kernel_size + ky) * kernel_size + kx;
                sum += input[input_idx] * weight[weight_idx];
            }
        }
    }

    if (bias) sum += bias[oc];
    output[idx] = sum;
}

Tensor conv2d_forward_cuda(
    Tensor input,
    Tensor weight,
    Tensor bias,
    int stride,
    int padding,
    int dilation,
    int groups
) {
    const int batch_size = input.size(0);
    const int in_channels = input.size(1);
    const int in_height = input.size(2);
    const int in_width = input.size(3);
    const int kernel_size = weight.size(2);
    const int out_channels = weight.size(0);

    const int out_height = (in_height + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1;
    const int out_width = (in_width + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1;

    auto output = torch::empty({batch_size, out_channels, out_height, out_width}, input.options());

    const int total_elements = batch_size * out_channels * out_height * out_width;
    const int block_size = 512;
    const int num_blocks = (total_elements + block_size - 1) / block_size;

    conv2d_forward_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        weight.data_ptr<float>(),
        bias.defined() ? bias.data_ptr<float>() : nullptr,
        output.data_ptr<float>(),
        batch_size,
        in_channels,
        out_channels,
        in_height,
        in_width,
        kernel_size,
        stride,
        padding,
        dilation,
        groups,
        out_height,
        out_width
    );

    return output;
}
"""

conv2d_cpp_source = """
torch::Tensor conv2d_forward_cuda(
    torch::Tensor input,
    torch::Tensor weight,
    torch::Tensor bias,
    int stride,
    int padding,
    int dilation,
    int groups
);
"""

conv2d_ext = load_inline(
    name='conv2d_ext',
    cpp_sources=conv2d_cpp_source,
    cuda_sources=conv2d_cuda_source,
    functions=['conv2d_forward_cuda'],
    verbose=True,
    extra_cuda_cflags=['-O3', '--use_fast_math']
)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, 
                 stride: int = 1, padding: int = 0, dilation: int = 1, 
                 groups: int = 1, bias: bool = False):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups
        
        self.weight = nn.Parameter(torch.empty(
            out_channels,
            in_channels // groups,
            kernel_size,
            kernel_size
        ))
        
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
            
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return conv2d_ext.conv2d_forward_cuda(
            x, 
            self.weight,
            self.bias if self.bias is not None else torch.Tensor(),
            self.stride,
            self.padding,
            self.dilation,
            self.groups
        )
```

Kernel 2 (runtime: 298.0 ms):
```
import torch
import torch.nn as nn
import math
from torch.utils.cpp_extension import load_inline

# Custom 3x3 convolution CUDA kernel implementation
conv2d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void conv2d_3x3_kernel(
    const float* __restrict__ input,
    const float* __restrict__ weight,
    float* __restrict__ output,
    const int in_channels,
    const int in_height,
    const int in_width,
    const int out_channels,
    const int out_height,
    const int out_width,
    const int batch_size
) {
    const int batch = blockIdx.x;
    const int out_c = blockIdx.y;
    const int out_h = blockIdx.z;
    const int out_w = threadIdx.x;

    if (batch >= batch_size || out_c >= out_channels || out_h >= out_height || out_w >= out_width) return;

    float sum = 0.0f;
    
    #pragma unroll
    for (int in_c = 0; in_c < in_channels; ++in_c) {
        #pragma unroll
        for (int i = 0; i < 3; ++i) {
            #pragma unroll
            for (int j = 0; j < 3; ++j) {
                const int in_h = out_h + i;
                const int in_w = out_w + j;
                
                if (in_h < in_height && in_w < in_width) {
                    const int input_idx = ((batch * in_channels + in_c) * in_height + in_h) * in_width + in_w;
                    const int weight_idx = ((out_c * in_channels + in_c) * 3 + i) * 3 + j;
                    sum += input[input_idx] * weight[weight_idx];
                }
            }
        }
    }

    const int output_idx = ((batch * out_channels + out_c) * out_height + out_h) * out_width + out_w;
    output[output_idx] = sum;
}

torch::Tensor conv2d_3x3_cuda(
    torch::Tensor input,
    torch::Tensor weight,
    int out_height,
    int out_width,
    int batch_size,
    int out_channels
) {
    auto output = torch::zeros({batch_size, out_channels, out_height, out_width}, input.options());
    
    const dim3 grid_dim(batch_size, out_channels, out_height);
    const dim3 block_dim(out_width);
    
    conv2d_3x3_kernel<<<grid_dim, block_dim>>>(
        input.data_ptr<float>(),
        weight.data_ptr<float>(),
        output.data_ptr<float>(),
        input.size(1),
        input.size(2),
        input.size(3),
        out_channels,
        out_height,
        out_width,
        batch_size
    );
    
    return output;
}
"""

conv2d_cpp_source = "torch::Tensor conv2d_3x3_cuda(torch::Tensor input, torch::Tensor weight, int out_height, int out_width, int batch_size, int out_channels);"

# Load the custom CUDA kernel
conv2d_3x3 = load_inline(
    name='conv2d_3x3',
    cpp_sources=conv2d_cpp_source,
    cuda_sources=conv2d_source,
    functions=['conv2d_3x3_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, 
                 stride: int = 1, padding: int = 0, dilation: int = 1, 
                 groups: int = 1, bias: bool = False):
        super().__init__()
        assert kernel_size == 3, "Only 3x3 kernels supported"
        assert stride == 1 and padding == 0, "Only stride=1 and padding=0 supported"
        assert dilation == 1 and groups == 1, "Dilation and groups not supported"
        assert not bias, "Bias not supported"

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        
        # Initialize weights using Kaiming initialization
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, 3, 3))
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, _, in_height, in_width = x.shape
        out_height = in_height - 2
        out_width = in_width - 2
        
        return conv2d_3x3.conv2d_3x3_cuda(
            x, 
            self.weight,
            out_height,
            out_width,
            batch_size,
            self.out_channels
        )
```
