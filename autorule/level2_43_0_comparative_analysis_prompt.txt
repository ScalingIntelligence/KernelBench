You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 8.98 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for fused logsumexp + ReLU
fused_kernel_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

__global__ void fused_logsumexp_relu_kernel(const float* input, float* output, int batch_size, int channels, int depth, int height, int width) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_elements = batch_size * depth * height * width;
    if (idx >= total_elements) return;

    int batch = idx / (depth * height * width);
    int remaining = idx % (depth * height * width);
    int d = remaining / (height * width);
    remaining = remaining % (height * width);
    int h = remaining / width;
    int w = remaining % width;

    float max_val = -INFINITY;
    for (int c = 0; c < channels; ++c) {
        int input_idx = batch * channels * depth * height * width +
                        c * depth * height * width +
                        d * height * width +
                        h * width +
                        w;
        float val = input[input_idx];
        max_val = fmaxf(max_val, val);
    }

    float sum_exp = 0.0f;
    for (int c = 0; c < channels; ++c) {
        int input_idx = batch * channels * depth * height * width +
                        c * depth * height * width +
                        d * height * width +
                        h * width +
                        w;
        float val = input[input_idx];
        sum_exp += expf(val - max_val);
    }

    float log_sum_exp = logf(sum_exp) + max_val;
    float result = fmaxf(0.0f, log_sum_exp);

    int output_idx = batch * depth * height * width +
                     d * height * width +
                     h * width +
                     w;
    output[output_idx] = result;
}

torch::Tensor fused_logsumexp_relu_cuda(torch::Tensor input) {
    auto input_contig = input.contiguous();
    auto batch_size = input_contig.size(0);
    auto channels = input_contig.size(1);
    auto depth = input_contig.size(2);
    auto height = input_contig.size(3);
    auto width = input_contig.size(4);
    auto output = torch::zeros({batch_size, 1, depth, height, width}, input_contig.options());

    int total_elements = batch_size * depth * height * width;
    const int block_size = 256;
    const int grid_size = (total_elements + block_size - 1) / block_size;

    fused_logsumexp_relu_kernel<<<grid_size, block_size>>>(
        input_contig.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size,
        channels,
        depth,
        height,
        width
    );

    return output;
}
"""

fused_kernel_cpp = "torch::Tensor fused_logsumexp_relu_cuda(torch::Tensor input);"

fused_logsumexp_relu = load_inline(
    name='fused_logsumexp_relu',
    cpp_sources=fused_kernel_cpp,
    cuda_sources=fused_kernel_source,
    functions=['fused_logsumexp_relu_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[],
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)
        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)
        self.fused_op = fused_logsumexp_relu

    def forward(self, x):
        x = self.conv(x)
        x = self.max_pool(x)
        x = self.fused_op.fused_logsumexp_relu_cuda(x)
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding]

batch_size = 4
in_channels = 32
out_channels = 64
depth, height, width = 32, 128, 128
kernel_size = 3
stride = 1
padding = 1
```

Kernel 2 (runtime: 8.49 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for fused max pool, logsumexp, and ReLU
fused_kernel_code = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <cmath>

__global__ void fused_maxpool_logsumexp_relu_kernel(
    const float* __restrict__ input,
    float* __restrict__ output,
    const int B,
    const int C_in,
    const int D_in, const int H_in, const int W_in,
    const int D_out, const int H_out, const int W_out
) {
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int total_elements = B * 1 * D_out * H_out * W_out;
    if (tid >= total_elements) return;

    // Decompose tid into batch, spatial indices
    const int b = tid / (D_out * H_out * W_out);
    const int remainder = tid % (D_out * H_out * W_out);
    const int d_out = remainder / (H_out * W_out);
    const int hw_remainder = remainder % (H_out * W_out);
    const int h_out = hw_remainder / W_out;
    const int w_out = hw_remainder % W_out;

    float sum_exp = 0.0f;

    for (int c = 0; c < C_in; ++c) {
        const int i_d_start = d_out * 2;
        const int i_h_start = h_out * 2;
        const int i_w_start = w_out * 2;

        float max_val = -INFINITY;

        for (int kd = 0; kd < 2; ++kd) {
            const int i_d = i_d_start + kd;
            if (i_d >= D_in) continue;
            
            for (int kh = 0; kh < 2; ++kh) {
                const int i_h = i_h_start + kh;
                if (i_h >= H_in) continue;
                
                for (int kw = 0; kw < 2; ++kw) {
                    const int i_w = i_w_start + kw;
                    if (i_w >= W_in) continue;
                    
                    const int input_offset = 
                        ((b * C_in + c) * D_in + i_d) * H_in * W_in +
                        i_h * W_in + i_w;
                    max_val = fmaxf(max_val, input[input_offset]);
                }
            }
        }

        sum_exp += expf(max_val);
    }

    const float log_sum_exp = logf(sum_exp);
    output[tid] = fmaxf(log_sum_exp, 0.0f);
}

torch::Tensor fused_maxpool_logsumexp_relu_cuda(torch::Tensor x) {
    TORCH_CHECK(x.is_contiguous(), "Input tensor must be contiguous");
    TORCH_CHECK(x.dim() == 5, "Input must be 5D (N, C, D, H, W)");

    const int B = x.size(0);
    const int C_in = x.size(1);
    const int D_in = x.size(2);
    const int H_in = x.size(3);
    const int W_in = x.size(4);

    const int D_out = (D_in + 1) / 2;
    const int H_out = (H_in + 1) / 2;
    const int W_out = (W_in + 1) / 2;

    auto output = torch::empty({B, 1, D_out, H_out, W_out}, x.options());
    const int total_elements = B * D_out * H_out * W_out;

    const int block_size = 256;
    const int grid_size = (total_elements + block_size - 1) / block_size;

    fused_maxpool_logsumexp_relu_kernel<<<grid_size, block_size>>>(
        x.data_ptr<float>(),
        output.data_ptr<float>(),
        B, C_in, D_in, H_in, W_in,
        D_out, H_out, W_out
    );

    return output;
}
"""

# Header for the C++ function
fused_header = "torch::Tensor fused_maxpool_logsumexp_relu_cuda(torch::Tensor x);"

# Load the CUDA extension
fused_module = load_inline(
    name='fused_ops',
    cpp_sources=fused_header,
    cuda_sources=fused_kernel_code,
    functions=['fused_maxpool_logsumexp_relu_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)
        self.fused_op = fused_module.fused_maxpool_logsumexp_relu_cuda

    def forward(self, x):
        x = self.conv(x)
        x = self.fused_op(x)
        return x
```
