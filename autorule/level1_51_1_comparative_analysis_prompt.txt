You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 14.7 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

argmax_kernel_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void argmax_dim1_kernel(const float* __restrict__ input, int64_t* __restrict__ output, int N, int M, int K) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int n = idx / K;
    int k = idx % K;

    if (n >= N || k >= K) return;

    const float* input_ptr = input + n * M * K + k;
    float max_val = -INFINITY;
    int max_idx = 0;

    #pragma unroll 4
    for (int m = 0; m < M; ++m) {
        float val = __ldg(input_ptr + m * K);
        if (val > max_val || (val == max_val && m < max_idx)) {
            max_val = val;
            max_idx = m;
        }
    }

    output[idx] = max_idx;
}

torch::Tensor argmax_dim1_cuda(torch::Tensor input) {
    auto sizes = input.sizes();
    int N = sizes[0];
    int M = sizes[1];
    int K = sizes[2];

    auto output = torch::empty({N, K}, torch::dtype(torch::kLong).device(input.device()));

    int total_elements = N * K;
    const int block_size = 256;
    int num_blocks = (total_elements + block_size - 1) / block_size;

    argmax_dim1_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        output.data_ptr<int64_t>(),
        N, M, K
    );

    return output;
}
"""

argmax_cpp_source = "torch::Tensor argmax_dim1_cuda(torch::Tensor input);"

argmax_extension = load_inline(
    name="argmax_extension",
    cpp_sources=argmax_cpp_source,
    cuda_sources=argmax_kernel_source,
    functions=["argmax_dim1_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_cuda_cflags=["-O3", "--use_fast_math"]
)

class ModelNew(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        self.dim = dim

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if x.dim() == 3 and self.dim == 1:
            x_contiguous = x.contiguous()
            return argmax_extension.argmax_dim1_cuda(x_contiguous)
        else:
            return torch.argmax(x, dim=self.dim)

batch_size = 128
dim1 = 4096
dim2 = 4095

def get_inputs():
    x = torch.rand(batch_size, dim1, dim2)
    return [x]

def get_init_inputs():
    return [1]
```

Kernel 2 (runtime: 14.7 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

argmax_cuda_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <cfloat>

template <int DIM>
__global__ void argmax_kernel(const float* __restrict__ input, int64_t* __restrict__ output, 
                              int batch_size, int dim1, int dim2) {
    if (DIM == 1) {
        // Optimized 2D grid layout for dimension 1 reduction
        const int b = blockIdx.x;
        const int d = blockIdx.y * blockDim.x + threadIdx.x;
        
        if (b >= batch_size || d >= dim2) return;

        const int base = b * dim1 * dim2 + d;
        float max_val = -FLT_MAX;
        int max_idx = 0;

        // Unrolled loop with coalesced memory access
        for (int i = 0; i < dim1; i += 4) {
            float val0 = __ldg(input + base + (i+0)*dim2);
            float val1 = __ldg(input + base + (i+1)*dim2);
            float val2 = __ldg(input + base + (i+2)*dim2);
            float val3 = __ldg(input + base + (i+3)*dim2);

            if (val0 > max_val) { max_val = val0; max_idx = i+0; }
            if (val1 > max_val) { max_val = val1; max_idx = i+1; }
            if (val2 > max_val) { max_val = val2; max_idx = i+2; }
            if (val3 > max_val) { max_val = val3; max_idx = i+3; }
        }

        output[b * dim2 + d] = max_idx;
    }
    else {  // DIM == 2
        // Optimized 1D grid for contiguous dimension reduction
        const int idx = blockIdx.x * blockDim.x + threadIdx.x;
        const int total = batch_size * dim1;
        if (idx >= total) return;

        const int b = idx / dim1;
        const int d = idx % dim1;
        const int base = b * dim1 * dim2 + d * dim2;

        float max_val = -FLT_MAX;
        int max_idx = 0;

        // Process 8 elements per iteration for better ILP
        for (int i = 0; i < dim2; i += 8) {
            int remaining = min(8, dim2 - i);
            for (int j = 0; j < remaining; ++j) {
                float val = __ldg(input + base + i + j);
                if (val > max_val) {
                    max_val = val;
                    max_idx = i + j;
                }
            }
        }

        output[idx] = max_idx;
    }
}

template __global__ void argmax_kernel<1>(const float*, int64_t*, int, int, int);
template __global__ void argmax_kernel<2>(const float*, int64_t*, int, int, int);

torch::Tensor argmax_cuda(torch::Tensor input, int dim) {
    TORCH_CHECK(input.dim() == 3, "Input must be a 3D tensor");
    TORCH_CHECK(dim == 1 || dim == 2, "dim must be 1 or 2");

    const auto sizes = input.sizes();
    const int batch_size = sizes[0];
    const int dim1 = sizes[1];
    const int dim2 = sizes[2];

    auto options = torch::TensorOptions().dtype(torch::kLong).device(input.device());
    torch::Tensor output;

    if (dim == 1) {
        output = torch::empty({batch_size, dim2}, options);
        // 2D grid: x=batch, y=d chunks
        const int block_size = 256;
        dim3 grid(batch_size, (dim2 + block_size - 1) / block_size);
        argmax_kernel<1><<<grid, block_size>>>(
            input.data_ptr<float>(),
            output.data_ptr<int64_t>(),
            batch_size,
            dim1,
            dim2
        );
    } else {
        output = torch::empty({batch_size, dim1}, options);
        // 1D grid with large blocks
        const int block_size = 512;
        const int num_blocks = (output.numel() + block_size - 1) / block_size;
        argmax_kernel<2><<<num_blocks, block_size>>>(
            input.data_ptr<float>(),
            output.data_ptr<int64_t>(),
            batch_size,
            dim1,
            dim2
        );
    }

    return output;
}
"""

argmax_cpp_source = "torch::Tensor argmax_cuda(torch::Tensor input, int dim);"

argmax_extension = load_inline(
    name='argmax_extension',
    cpp_sources=argmax_cpp_source,
    cuda_sources=argmax_cuda_source,
    functions=['argmax_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=['-lcudart', '-lcuda']
)

class ModelNew(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        self.dim = dim
        self.argmax_cuda = argmax_extension.argmax_cuda

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.argmax_cuda(x, self.dim)

batch_size = 128
dim1 = 4096
dim2 = 4095

def get_inputs():
    x = torch.rand(batch_size, dim1, dim2).cuda()
    return [x]

def get_init_inputs():
    return [1]
```
