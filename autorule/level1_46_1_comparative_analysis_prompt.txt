You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 13.8 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

avg_pool3d_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void avg_pool3d_kernel(const float* __restrict__ input, float* __restrict__ output,
                                 int B, int C, int D, int H, int W,
                                 int D_out, int H_out, int W_out,
                                 int kernel_size, int stride, int padding) {
    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_elements = B * C * D_out * H_out * W_out;
    if (globalIdx >= total_elements) return;

    // Compute indices
    int b = globalIdx / (C * D_out * H_out * W_out);
    int remainder = globalIdx % (C * D_out * H_out * W_out);
    int c = remainder / (D_out * H_out * W_out);
    remainder %= (D_out * H_out * W_out);
    int d_out = remainder / (H_out * W_out);
    remainder %= (H_out * W_out);
    int h_out = remainder / W_out;
    int w_out = remainder % W_out;

    // Calculate input window bounds
    int d_start = d_out * stride - padding;
    int h_start = h_out * stride - padding;
    int w_start = w_out * stride - padding;

    float sum = 0.0f;

    for(int kd=0; kd<kernel_size; ++kd) {
        int id = d_start + kd;
        if(id < 0 || id >= D) continue;
        for(int kh=0; kh<kernel_size; ++kh) {
            int ih = h_start + kh;
            if(ih < 0 || ih >= H) continue;
            for(int kw=0; kw<kernel_size; ++kw) {
                int iw = w_start + kw;
                if(iw < 0 || iw >= W) continue;
                
                int input_idx = ((b*C*D + c*D + id)*H + ih)*W + iw;
                sum += input[input_idx];
            }
        }
    }

    output[globalIdx] = sum / static_cast<float>(kernel_size*kernel_size*kernel_size);
}

torch::Tensor avg_pool3d_cuda(torch::Tensor input, int kernel_size, int stride, int padding) {
    auto sizes = input.sizes();
    int B = sizes[0], C = sizes[1], D = sizes[2], H = sizes[3], W = sizes[4];

    int D_out = (D + 2*padding - kernel_size)/stride + 1;
    int H_out = (H + 2*padding - kernel_size)/stride + 1;
    int W_out = (W + 2*padding - kernel_size)/stride + 1;

    auto output = torch::empty({B, C, D_out, H_out, W_out}, input.options());

    const int block_size = 256;
    dim3 grid((output.numel() + block_size-1)/block_size);
    avg_pool3d_kernel<<<grid, block_size>>>(
        input.contiguous().data_ptr<float>(),
        output.data_ptr<float>(),
        B, C, D, H, W,
        D_out, H_out, W_out,
        kernel_size, stride, padding
    );

    return output;
}
"""

avg_pool3d = load_inline(
    name='avg_pool3d',
    cpp_sources="torch::Tensor avg_pool3d_cuda(torch::Tensor input, int kernel_size, int stride, int padding);",
    cuda_sources=avg_pool3d_source,
    functions=['avg_pool3d_cuda'],
    verbose=False
)

class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):
        super().__init__()
        self.kernel_size = kernel_size
        self.stride = stride if stride is not None else kernel_size
        self.padding = padding

    def forward(self, x):
        return avg_pool3d.avg_pool3d_cuda(x, self.kernel_size, self.stride, self.padding)
```

Kernel 2 (runtime: 15.3 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

avg_pool3d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void avg_pool3d_kernel(
    const float* input,
    float* output,
    int batch_size,
    int channels,
    int input_depth,
    int input_height,
    int input_width,
    int output_depth,
    int output_height,
    int output_width,
    int kernel_d,
    int kernel_h,
    int kernel_w,
    int stride_d,
    int stride_h,
    int stride_w,
    int pad_d,
    int pad_h,
    int pad_w
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int total_elements = batch_size * channels * output_depth * output_height * output_width;
    if (tid >= total_elements) return;

    // Compute 5D indices
    int b = tid / (channels * output_depth * output_height * output_width);
    int rem = tid % (channels * output_depth * output_height * output_width);
    int c = rem / (output_depth * output_height * output_width);
    rem = rem % (output_depth * output_height * output_width);
    int oz = rem / (output_height * output_width);
    rem = rem % (output_height * output_width);
    int oy = rem / output_width;
    int ox = rem % output_width;

    int input_z_start = oz * stride_d - pad_d;
    int input_y_start = oy * stride_h - pad_h;
    int input_x_start = ox * stride_w - pad_w;

    float sum = 0.0f;

    for (int kz = 0; kz < kernel_d; ++kz) {
        int input_z = input_z_start + kz;
        for (int ky = 0; ky < kernel_h; ++ky) {
            int input_y = input_y_start + ky;
            for (int kx = 0; kx < kernel_w; ++kx) {
                int input_x = input_x_start + kx;
                if (input_z >= 0 && input_z < input_depth &&
                    input_y >= 0 && input_y < input_height &&
                    input_x >= 0 && input_x < input_width) {
                    int input_idx = b * channels * input_depth * input_height * input_width +
                                    c * input_depth * input_height * input_width +
                                    input_z * input_height * input_width +
                                    input_y * input_width +
                                    input_x;
                    sum += input[input_idx];
                }
            }
        }
    }

    float avg = sum / (kernel_d * kernel_h * kernel_w);
    int output_idx = b * channels * output_depth * output_height * output_width +
                     c * output_depth * output_height * output_width +
                     oz * output_height * output_width +
                     oy * output_width +
                     ox;
    output[output_idx] = avg;
}

torch::Tensor avg_pool3d_cuda(
    torch::Tensor input,
    int kernel_d, int kernel_h, int kernel_w,
    int stride_d, int stride_h, int stride_w,
    int pad_d, int pad_h, int pad_w
) {
    auto batch_size = input.size(0);
    auto channels = input.size(1);
    auto input_depth = input.size(2);
    auto input_height = input.size(3);
    auto input_width = input.size(4);

    int output_depth = (input_depth + 2 * pad_d - kernel_d) / stride_d + 1;
    int output_height = (input_height + 2 * pad_h - kernel_h) / stride_h + 1;
    int output_width = (input_width + 2 * pad_w - kernel_w) / stride_w + 1;

    auto output = torch::zeros({batch_size, channels, output_depth, output_height, output_width}, input.options());

    int total_elements = output.numel();
    int block_size = 256;
    int num_blocks = (total_elements + block_size - 1) / block_size;

    avg_pool3d_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size,
        channels,
        input_depth,
        input_height,
        input_width,
        output_depth,
        output_height,
        output_width,
        kernel_d,
        kernel_h,
        kernel_w,
        stride_d,
        stride_h,
        stride_w,
        pad_d,
        pad_h,
        pad_w
    );

    return output;
}
"""

avg_pool3d_cpp_source = "torch::Tensor avg_pool3d_cuda(torch::Tensor input, int kernel_d, int kernel_h, int kernel_w, int stride_d, int stride_h, int stride_w, int pad_d, int pad_h, int pad_w);"

avg_pool3d = load_inline(
    name="avg_pool3d",
    cpp_sources=avg_pool3d_cpp_source,
    cuda_sources=avg_pool3d_source,
    functions=["avg_pool3d_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):
        super().__init__()
        self.kernel_size = self._triple(kernel_size)
        self.stride = self._triple(stride) if stride is not None else self.kernel_size
        self.padding = self._triple(padding)
        self.avg_pool3d = avg_pool3d

    @staticmethod
    def _triple(value):
        if isinstance(value, int):
            return (value, value, value)
        elif isinstance(value, (tuple, list)) and len(value) == 3:
            return tuple(value)
        else:
            raise ValueError("Value must be an int or a 3-element tuple/list")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x.contiguous()
        return self.avg_pool3d.avg_pool3d_cuda(
            x,
            self.kernel_size[0], self.kernel_size[1], self.kernel_size[2],
            self.stride[0], self.stride[1], self.stride[2],
            self.padding[0], self.padding[1], self.padding[2]
        )
```
