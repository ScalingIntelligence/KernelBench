You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 7.09 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom fused kernel implementation for max, subtraction, and GELU
fused_kernel_code = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <math.h>

#define BLOCK_SIZE 256
#define GELU_COEF_A 0.7978845608f  // sqrt(2/pi)
#define GELU_COEF_B 0.044715f

__device__ __forceinline__ float gelu_approx(float x) {
    return 0.5f * x * (1.0f + tanhf(GELU_COEF_A * (x + GELU_COEF_B * x * x * x)));
}

__global__ void fused_ops_kernel(
    const float* input,
    float* output,
    int num_rows,
    int row_size
) {
    extern __shared__ float smem[];
    float* max_smem = smem;

    int row_idx = blockIdx.x;
    int tid = threadIdx.x;

    if (row_idx >= num_rows) return;

    const float* row_start = input + row_idx * row_size;
    
    // Initialize local max
    float local_max = -INFINITY;

    // Process elements with stride BLOCK_SIZE
    for (int i = tid; i < row_size; i += BLOCK_SIZE) {
        float val = row_start[i];
        local_max = fmaxf(local_max, val);
    }

    // Initialize shared memory for max
    max_smem[tid] = local_max;
    __syncthreads();

    // Parallel reduction for max
    for (int s = blockDim.x/2; s > 0; s >>= 1) {
        if (tid < s) {
            max_smem[tid] = fmaxf(max_smem[tid], max_smem[tid + s]);
        }
        __syncthreads();
    }

    if (tid == 0) {
        float row_max = max_smem[0];
        float result = row_max - row_max;  // Results in zero
        output[row_idx] = gelu_approx(result);
    }
}

torch::Tensor fused_operations_cuda(torch::Tensor input) {
    int num_rows = input.size(0);
    int row_size = input.size(1);
    
    auto output = torch::zeros({num_rows, 1}, input.options());
    
    dim3 grid(num_rows);
    dim3 block(BLOCK_SIZE);
    size_t smem_size = BLOCK_SIZE * sizeof(float);
    
    fused_ops_kernel<<<grid, block, smem_size>>>(
        input.data_ptr<float>(),
        output.data_ptr<float>(),
        num_rows,
        row_size
    );
    
    return output;
}
"""

fused_kernel_cpp = "torch::Tensor fused_operations_cuda(torch::Tensor input);"

fused_op = load_inline(
    name='fused_op',
    cpp_sources=fused_kernel_cpp,
    cuda_sources=fused_kernel_code,
    functions=['fused_operations_cuda'],
    verbose=True,
    extra_cuda_cflags=['-O2']
)

class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, max_dim):
        super(ModelNew, self).__init__()
        self.gemm = nn.Linear(in_features, out_features)
        self.max_dim = max_dim  # Preserve for compatibility
        
    def forward(self, x):
        x = self.gemm(x)
        x = fused_op.fused_operations_cuda(x)
        return x
```

Kernel 2 (runtime: 6.98 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for fused max reduction, mean subtraction, and GELU
fused_ops_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <math.h>

__global__ void fused_ops_kernel(const float* input, float* output, int O) {
    int row = blockIdx.x;
    int tid = threadIdx.x;

    extern __shared__ float shared_max[];

    // Load and find max in parallel
    float max_val = -INFINITY;
    for(int i = tid; i < O; i += blockDim.x) {
        float val = input[row * O + i];
        max_val = fmaxf(max_val, val);
    }
    shared_max[tid] = max_val;
    __syncthreads();

    // Parallel max reduction
    for(int s = blockDim.x/2; s > 0; s >>= 1) {
        if(tid < s) {
            shared_max[tid] = fmaxf(shared_max[tid], shared_max[tid + s]);
        }
        __syncthreads();
    }

    // Final calculations and write result
    if(tid == 0) {
        float row_max = shared_max[0];
        float mean = row_max;
        float diff = row_max - mean;
        // GELU approximation for efficiency
        float gelu = 0.5f * diff * (1.0f + tanhf(0.7978845608f * (diff + 0.044715f * diff * diff * diff)));
        output[row] = gelu;
    }
}

torch::Tensor fused_ops_cuda(torch::Tensor input) {
    int B = input.size(0);
    int O = input.size(1);
    auto output = torch::empty({B, 1}, input.options());

    const int threads = 256;
    int shared_mem = threads * sizeof(float);
    
    fused_ops_kernel<<<B, threads, shared_mem>>>(
        input.data_ptr<float>(),
        output.data_ptr<float>(),
        O
    );

    return output;
}
"""

fused_ops_cpp_source = "torch::Tensor fused_ops_cuda(torch::Tensor input);"

# Compile the CUDA extension
fused_ops = load_inline(
    name='fused_ops',
    cpp_sources=fused_ops_cpp_source,
    cuda_sources=fused_ops_source,
    functions=['fused_ops_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, max_dim):
        super(ModelNew, self).__init__()
        self.gemm = nn.Linear(in_features, out_features)
        assert max_dim == 1, "Custom kernel only supports max_dim=1"
        
    def forward(self, x):
        x = self.gemm(x)
        x = fused_ops.fused_ops_cuda(x)
        return x
```
