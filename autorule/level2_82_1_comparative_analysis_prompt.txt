You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 14.1 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define optimized fused tanh+scale+bias+maxpool CUDA kernel
fused_kernel_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <cmath>

__global__ void fused_tanh_scale_bias_maxpool_kernel(
    const float* input, float* output, const float* bias, float scaling_factor,
    int N, int C, int H_in, int W_in, int H_out, int W_out, int pool_size) {
    
    int n = blockIdx.z;
    int c = blockIdx.y;
    int spatial_idx = blockIdx.x * blockDim.x + threadIdx.x;
    int spatial_total = H_out * W_out;

    if (n >= N || c >= C || spatial_idx >= spatial_total) return;

    float current_bias = bias[c];
    int h_out = spatial_idx / W_out;
    int w_out = spatial_idx % W_out;
    int h_start = h_out * pool_size;
    int w_start = w_out * pool_size;

    float max_val = -INFINITY;
    int base_input_idx = n * C * H_in * W_in + c * H_in * W_in;

    #pragma unroll
    for (int h = 0; h < pool_size; ++h) {
        int h_in = h_start + h;
        if (h_in >= H_in) continue;
        #pragma unroll
        for (int w = 0; w < pool_size; ++w) {
            int w_in = w_start + w;
            if (w_in >= W_in) continue;

            float val = input[base_input_idx + h_in * W_in + w_in];
            val = tanhf(val) * scaling_factor + current_bias;
            max_val = fmaxf(max_val, val);
        }
    }

    output[n * C * H_out * W_out + c * H_out * W_out + h_out * W_out + w_out] = max_val;
}

torch::Tensor fused_tanh_scale_bias_maxpool_cuda(
    torch::Tensor input, torch::Tensor bias, float scaling_factor, int pool_size) {

    TORCH_CHECK(input.device().is_cuda(), "Input must be a CUDA tensor");
    TORCH_CHECK(bias.device().is_cuda(), "Bias must be a CUDA tensor");
    TORCH_CHECK(input.is_contiguous(), "Input must be contiguous");
    TORCH_CHECK(bias.is_contiguous(), "Bias must be contiguous");

    auto sizes = input.sizes();
    int N = sizes[0], C = sizes[1], H_in = sizes[2], W_in = sizes[3];
    TORCH_CHECK(bias.size(0) == C, "Bias dimension 0 must match input channels");
    TORCH_CHECK(bias.size(1) == 1 && bias.size(2) == 1, "Bias must be (C,1,1)");

    int H_out = H_in / pool_size;
    int W_out = W_in / pool_size;
    auto output = torch::empty({N, C, H_out, W_out}, input.options());

    int spatial_total = H_out * W_out;
    const int threads_per_block = 256;
    int num_blocks_x = (spatial_total + threads_per_block - 1) / threads_per_block;
    dim3 grid(num_blocks_x, C, N);

    fused_tanh_scale_bias_maxpool_kernel<<<grid, threads_per_block>>>(
        input.data_ptr<float>(),
        output.data_ptr<float>(),
        bias.data_ptr<float>(),
        scaling_factor,
        N, C, H_in, W_in, H_out, W_out, pool_size
    );

    return output;
}
"""

fused_kernel_cpp = "torch::Tensor fused_tanh_scale_bias_maxpool_cuda(torch::Tensor input, torch::Tensor bias, float scaling_factor, int pool_size);"

# Compile the fused kernel
fused_ops = load_inline(
    name='fused_ops',
    cpp_sources=fused_kernel_cpp,
    cuda_sources=fused_kernel_source,
    functions=['fused_tanh_scale_bias_maxpool_cuda'],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.scaling_factor = scaling_factor
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.pool_kernel_size = pool_kernel_size
        self.fused_ops = fused_ops

    def forward(self, x):
        x = self.conv(x)
        x = self.fused_ops.fused_tanh_scale_bias_maxpool_cuda(
            x, self.bias, self.scaling_factor, self.pool_kernel_size
        )
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, height, width, device='cuda')]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]

# Constants from original implementation
batch_size = 128
in_channels = 8
out_channels = 64
height, width = 256, 256
kernel_size = 3
scaling_factor = 2.0
bias_shape = (out_channels, 1, 1)
pool_kernel_size = 4
```

Kernel 2 (runtime: 14.3 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

fused_ops_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void fused_tanh_scale_bias_max_pool_kernel(
    const float* input,
    const float* bias,
    float scaling_factor,
    float* output,
    int N, int C, int H_in, int W_in, int H_out, int W_out, int kernel_size
) {
    const int index = blockIdx.x * blockDim.x + threadIdx.x;
    const int total_elements = N * C * H_out * W_out;
    if (index >= total_elements) return;

    const int n = index / (C * H_out * W_out);
    const int rem = index % (C * H_out * W_out);
    const int c = rem / (H_out * W_out);
    const int hw = rem % (H_out * W_out);
    const int h_out = hw / W_out;
    const int w_out = hw % W_out;

    float max_val = -INFINITY;
    for (int i = 0; i < kernel_size; ++i) {
        for (int j = 0; j < kernel_size; ++j) {
            const int h_in = h_out * 4 + i;
            const int w_in = w_out * 4 + j;
            if (h_in < H_in && w_in < W_in) {
                const int input_idx = ((n * C + c) * H_in + h_in) * W_in + w_in;
                const float val = input[input_idx];
                
                // Apply tanh, scale, add bias
                const float tanh_val = tanhf(val);
                const float scaled_val = tanh_val * scaling_factor;
                const float biased_val = scaled_val + bias[c];
                
                if (biased_val > max_val) {
                    max_val = biased_val;
                }
            }
        }
    }

    output[index] = max_val;
}

torch::Tensor fused_tanh_scale_bias_max_pool_cuda(
    torch::Tensor input,
    torch::Tensor bias,
    float scaling_factor,
    int kernel_size
) {
    TORCH_CHECK(input.dim() == 4, "Input must be 4D");
    TORCH_CHECK(bias.dim() == 3, "Bias must be 3D (C,1,1)");
    TORCH_CHECK(scaling_factor > 0, "Scaling factor must be positive");
    TORCH_CHECK(kernel_size > 0, "Kernel size must be positive");

    const int N = input.size(0);
    const int C = input.size(1);
    const int H_in = input.size(2);
    const int W_in = input.size(3);
    const int H_out = H_in / kernel_size;
    const int W_out = W_in / kernel_size;

    auto output = torch::empty({N, C, H_out, W_out}, input.options());

    const int total_elements = N * C * H_out * W_out;
    const int threads_per_block = 256;
    const int blocks_per_grid = (total_elements + threads_per_block - 1) / threads_per_block;

    fused_tanh_scale_bias_max_pool_kernel<<<blocks_per_grid, threads_per_block>>>(
        input.data_ptr<float>(),
        bias.data_ptr<float>(),
        scaling_factor,
        output.data_ptr<float>(),
        N, C, H_in, W_in, H_out, W_out, kernel_size
    );

    return output;
}
"""

fused_ops_cpp = "torch::Tensor fused_tanh_scale_bias_max_pool_cuda(torch::Tensor input, torch::Tensor bias, float scaling_factor, int kernel_size);"

fused_ops = load_inline(
    name='fused_ops',
    cpp_sources=fused_ops_cpp,
    cuda_sources=fused_ops_source,
    functions=['fused_tanh_scale_bias_max_pool_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.scaling_factor = scaling_factor
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.pool_kernel_size = pool_kernel_size

    def forward(self, x):
        x = self.conv(x)
        x = fused_ops.fused_tanh_scale_bias_max_pool_cuda(
            x, self.bias, self.scaling_factor, self.pool_kernel_size
        )
        return x
```
