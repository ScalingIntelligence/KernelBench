You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 1190.0 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

conv_transpose3d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x " must be a CUDA tensor")
#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x " must be contiguous")

__global__ void conv_transpose3d_kernel(
    const float* input, const float* weight, const float* bias,
    float* output,
    int batch_size, int in_channels, int out_channels,
    int in_depth, int in_height, int in_width,
    int out_depth, int out_height, int out_width,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
) {
    const int group_size = out_channels / groups;
    const int in_channels_per_group = in_channels / groups;
    
    const int output_idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (output_idx >= batch_size * out_channels * out_depth * out_height * out_width) return;

    // Decompose output index
    const int n = output_idx / (out_channels * out_depth * out_height * out_width);
    const int c_out = (output_idx / (out_depth * out_height * out_width)) % out_channels;
    const int od = (output_idx / (out_height * out_width)) % out_depth;
    const int oh = (output_idx / out_width) % out_height;
    const int ow = output_idx % out_width;

    const int group_id = c_out / group_size;
    float sum = 0.0f;

    for (int kd = 0; kd < kernel_size; ++kd) {
        for (int kh = 0; kh < kernel_size; ++kh) {
            for (int kw = 0; kw < kernel_size; ++kw) {
                const int id = (od - kd * dilation + padding) / stride;
                const int ih = (oh - kh * dilation + padding) / stride;
                const int iw = (ow - kw * dilation + padding) / stride;

                if (id < 0 || id >= in_depth || ih < 0 || ih >= in_height || iw < 0 || iw >= in_width) continue;
                if ((od - kd * dilation + padding) % stride != 0) continue;
                if ((oh - kh * dilation + padding) % stride != 0) continue;
                if ((ow - kw * dilation + padding) % stride != 0) continue;

                for (int c_in = 0; c_in < in_channels_per_group; ++c_in) {
                    const int input_idx = n * in_channels * in_depth * in_height * in_width +
                                        (group_id * in_channels_per_group + c_in) * in_depth * in_height * in_width +
                                        id * in_height * in_width +
                                        ih * in_width +
                                        iw;

                    const int weight_idx = c_in * group_size * kernel_size * kernel_size * kernel_size +
                                         (c_out % group_size) * kernel_size * kernel_size * kernel_size +
                                         kd * kernel_size * kernel_size +
                                         kh * kernel_size +
                                         kw;

                    sum += input[input_idx] * weight[weight_idx];
                }
            }
        }
    }

    if (bias) sum += bias[c_out];
    output[output_idx] = sum;
}

torch::Tensor conv_transpose3d_forward(
    torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
) {
    CHECK_CUDA(input); CHECK_CONTIGUOUS(input);
    CHECK_CUDA(weight); CHECK_CONTIGUOUS(weight);
    if (bias.has_value()) {
        auto bias_tensor = bias.value();
        CHECK_CUDA(bias_tensor);
        CHECK_CONTIGUOUS(bias_tensor);
    }

    const int batch_size = input.size(0);
    const int in_channels = input.size(1);
    const int in_depth = input.size(2);
    const int in_height = input.size(3);
    const int in_width = input.size(4);
    
    const int out_channels = weight.size(1) * groups;
    const int out_depth = (in_depth - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;
    const int out_height = (in_height - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;
    const int out_width = (in_width - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;

    auto output = torch::zeros({batch_size, out_channels, out_depth, out_height, out_width}, input.options());
    const int num_elements = output.numel();
    
    const int threads = 256;
    const int blocks = (num_elements + threads - 1) / threads;

    conv_transpose3d_kernel<<<blocks, threads>>>(
        input.data_ptr<float>(),
        weight.data_ptr<float>(),
        bias.has_value() ? bias.value().data_ptr<float>() : nullptr,
        output.data_ptr<float>(),
        batch_size, in_channels, out_channels,
        in_depth, in_height, in_width,
        out_depth, out_height, out_width,
        kernel_size, stride, padding, output_padding,
        dilation, groups
    );

    return output;
}
"""

conv_transpose3d_cpp_source = """
#include <torch/extension.h>
#include <torch/library.h>

torch::Tensor conv_transpose3d_forward(
    torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
);
"""

conv_transpose3d = load_inline(
    name="conv_transpose3d",
    cpp_sources=conv_transpose3d_cpp_source,
    cuda_sources=conv_transpose3d_source,
    functions=["conv_transpose3d_forward"],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, 
                 padding: int = 0, output_padding: int = 0, dilation: int = 1, 
                 groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.output_padding = output_padding
        self.dilation = dilation
        self.groups = groups
        
        self.weight = nn.Parameter(torch.empty(
            in_channels,
            out_channels // groups,
            kernel_size,
            kernel_size,
            kernel_size
        ))
        
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
            
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=5**0.5)
        if self.bias is not None:
            nn.init.zeros_(self.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return conv_transpose3d.conv_transpose3d_forward(
            x, self.weight, self.bias,
            self.kernel_size, self.stride, self.padding, self.output_padding,
            self.dilation, self.groups
        )
```

Kernel 2 (runtime: 909.0 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

conv_transpose3d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x " must be a CUDA tensor")
#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x " must be contiguous")

__global__ void conv_transpose3d_kernel(
    const float* __restrict__ input,
    const float* __restrict__ weight,
    const float* __restrict__ bias,
    float* __restrict__ output,
    int batch_size, int in_channels, int out_channels,
    int in_depth, int in_height, int in_width,
    int out_depth, int out_height, int out_width,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
) {
    const int group_size = out_channels / groups;
    const int in_channels_per_group = in_channels / groups;
    
    const int output_idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (output_idx >= batch_size * out_channels * out_depth * out_height * out_width) return;

    // Decompose output index
    const int n = output_idx / (out_channels * out_depth * out_height * out_width);
    const int c_out = (output_idx / (out_depth * out_height * out_width)) % out_channels;
    const int od = (output_idx / (out_height * out_width)) % out_depth;
    const int oh = (output_idx / out_width) % out_height;
    const int ow = output_idx % out_width;

    const int group_id = c_out / group_size;
    float sum = 0.0f;

    // Precompute group-related indices
    const int input_base = n * in_channels * in_depth * in_height * in_width 
                         + group_id * in_channels_per_group * in_depth * in_height * in_width;
    const int c_out_group = c_out % group_size;
    
    for (int c_in = 0; c_in < in_channels_per_group; ++c_in) {
        const int weight_base = c_in * group_size * kernel_size * kernel_size * kernel_size
                              + c_out_group * kernel_size * kernel_size * kernel_size;
        
        for (int kd = 0; kd < kernel_size; ++kd) {
            const int id = (od - kd * dilation + padding) / stride;
            const int valid_d = (od - kd * dilation + padding) % stride == 0;
            if (id < 0 || id >= in_depth) continue;

            for (int kh = 0; kh < kernel_size; ++kh) {
                const int ih = (oh - kh * dilation + padding) / stride;
                const int valid_h = (oh - kh * dilation + padding) % stride == 0;
                if (ih < 0 || ih >= in_height) continue;

                for (int kw = 0; kw < kernel_size; ++kw) {
                    const int iw = (ow - kw * dilation + padding) / stride;
                    const int valid_w = (ow - kw * dilation + padding) % stride == 0;
                    if (iw < 0 || iw >= in_width) continue;

                    if (!(valid_d && valid_h && valid_w)) continue;

                    const int input_idx = input_base 
                                       + c_in * in_depth * in_height * in_width
                                       + id * in_height * in_width 
                                       + ih * in_width 
                                       + iw;

                    const int weight_idx = weight_base 
                                         + kd * kernel_size * kernel_size 
                                         + kh * kernel_size 
                                         + kw;

                    sum += input[input_idx] * weight[weight_idx];
                }
            }
        }
    }

    if (bias) sum += bias[c_out];
    output[output_idx] = sum;
}

torch::Tensor conv_transpose3d_forward(
    torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
) {
    CHECK_CUDA(input); CHECK_CONTIGUOUS(input);
    CHECK_CUDA(weight); CHECK_CONTIGUOUS(weight);
    if (bias.has_value()) {
        auto bias_tensor = bias.value();
        CHECK_CUDA(bias_tensor);
        CHECK_CONTIGUOUS(bias_tensor);
    }

    const int batch_size = input.size(0);
    const int in_channels = input.size(1);
    const int in_depth = input.size(2);
    const int in_height = input.size(3);
    const int in_width = input.size(4);
    
    const int out_channels = weight.size(1) * groups;
    const int out_depth = (in_depth - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;
    const int out_height = (in_height - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;
    const int out_width = (in_width - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1;

    auto output = torch::zeros({batch_size, out_channels, out_depth, out_height, out_width}, input.options());
    const int num_elements = output.numel();
    
    const int threads = 512;
    const int blocks = (num_elements + threads - 1) / threads;

    conv_transpose3d_kernel<<<blocks, threads>>>(
        input.data_ptr<float>(),
        weight.data_ptr<float>(),
        bias.has_value() ? bias.value().data_ptr<float>() : nullptr,
        output.data_ptr<float>(),
        batch_size, in_channels, out_channels,
        in_depth, in_height, in_width,
        out_depth, out_height, out_width,
        kernel_size, stride, padding, output_padding,
        dilation, groups
    );

    return output;
}
"""

conv_transpose3d_cpp_source = """
#include <torch/extension.h>
#include <torch/library.h>

torch::Tensor conv_transpose3d_forward(
    torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias,
    int kernel_size, int stride, int padding, int output_padding,
    int dilation, int groups
);
"""

conv_transpose3d = load_inline(
    name="conv_transpose3d",
    cpp_sources=conv_transpose3d_cpp_source,
    cuda_sources=conv_transpose3d_source,
    functions=["conv_transpose3d_forward"],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, 
                 padding: int = 0, output_padding: int = 0, dilation: int = 1, 
                 groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.output_padding = output_padding
        self.dilation = dilation
        self.groups = groups
        
        self.weight = nn.Parameter(torch.empty(
            in_channels,
            out_channels // groups,
            kernel_size,
            kernel_size,
            kernel_size
        ))
        
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
            
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=5**0.5)
        if self.bias is not None:
            nn.init.zeros_(self.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return conv_transpose3d.conv_transpose3d_forward(
            x, self.weight, self.bias,
            self.kernel_size, self.stride, self.padding, self.output_padding,
            self.dilation, self.groups
        )
```
