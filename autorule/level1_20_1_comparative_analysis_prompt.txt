You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 18.7 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* x, float* out, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        out[idx] = x[idx] > 0.0f ? x[idx] : x[idx] * negative_slope;
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor x, float negative_slope) {
    auto out = torch::empty_like(x);
    int size = x.numel();
    
    const int block_size = 256;
    int num_blocks = (size + block_size - 1) / block_size;
    
    leaky_relu_kernel<<<num_blocks, block_size>>>(
        x.data_ptr<float>(),
        out.data_ptr<float>(),
        size,
        negative_slope
    );
    
    return out;
}
"""

leaky_relu_cpp_source = "torch::Tensor leaky_relu_cuda(torch::Tensor x, float negative_slope);"

# Compile the inline CUDA code
leaky_relu_extension = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    """
    Optimized LeakyReLU implementation with custom CUDA kernel
    """
    def __init__(self, negative_slope: float = 0.01):
        super().__init__()
        self.negative_slope = negative_slope
        self.leaky_relu_cuda = leaky_relu_extension.leaky_relu_cuda

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.leaky_relu_cuda(x, self.negative_slope)
```

Kernel 2 (runtime: 12.2 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

leaky_relu_add_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

extern "C" {
    __global__ void fused_add_leaky_relu_kernel(float* input_output, float scalar, float negative_slope, int num_elements) {
        extern __shared__ float shared_mem[];
        int tid = blockIdx.x * blockDim.x + threadIdx.x;
        int lane = threadIdx.x;

        if (tid >= num_elements) return;

        float val = input_output[tid] + scalar;
        float result;

        if (val > 0.f) {
            result = val;
        } else {
            result = val * negative_slope;
        }

        shared_mem[lane] = result;
        __syncthreads();

        if (lane == 0) {
            input_output[tid] = shared_mem[0];
        }
    }

    torch::Tensor fused_add_leaky_relu_cuda(torch::Tensor x, float scalar, float negative_slope) {
        auto num_elements = x.numel();
        const int threads_per_block = 1024;
        const int blocks_per_grid = (num_elements + threads_per_block - 1) / threads_per_block;

        fused_add_leaky_relu_kernel<<<blocks_per_grid, threads_per_block, threads_per_block * sizeof(float)>>>(
            x.data_ptr<float>(),
            scalar,
            negative_slope,
            num_elements
        );

        return x;
    }
}
"""

leaky_relu_add_header = """
extern "C" {
    torch::Tensor fused_add_leaky_relu_cuda(torch::Tensor x, float scalar, float negative_slope);
}
"""

leaky_relu_add = load_inline(
    name='fused_add_leaky_relu',
    cpp_sources=leaky_relu_add_header,
    cuda_sources=leaky_relu_add_source,
    functions=['fused_add_leaky_relu_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, negative_slope: float = 0.01):
        super().__init__()
        self.scalar = nn.Parameter(torch.tensor(negative_slope))
    
    def forward(self, x):
        return leaky_relu_add.fused_add_leaky_relu_cuda(x, self.scalar.item(), self.scalar.item())
```
