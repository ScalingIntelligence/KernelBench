You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 23.2 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

fused_op_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void fused_scale_pool_bias_scale_kernel(
    const float* input,
    const float* bias,
    float scale1,
    float scale2,
    float* output,
    int B,
    int C,
    int D,
    int H,
    int W
) {
    int D_pool = D / 2;
    int H_pool = H / 2;
    int W_pool = W / 2;
    int total_elements = B * C * D_pool * H_pool * W_pool;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx >= total_elements) return;

    // Decompose linear index into 5D coordinates
    int elements_per_batch = C * D_pool * H_pool * W_pool;
    int b = idx / elements_per_batch;
    int remainder = idx % elements_per_batch;

    int elements_per_channel = D_pool * H_pool * W_pool;
    int c = remainder / elements_per_channel;
    remainder %= elements_per_channel;

    int elements_per_depth = H_pool * W_pool;
    int d_pool = remainder / elements_per_depth;
    remainder %= elements_per_depth;

    int h_pool = remainder / W_pool;
    int w_pool = remainder % W_pool;

    // Input window starting indices
    int d_start = d_pool * 2;
    int h_start = h_pool * 2;
    int w_start = w_pool * 2;

    float sum = 0.0f;
    for(int i = 0; i < 2; ++i) {
        for(int j = 0; j < 2; ++j) {
            for(int k = 0; k < 2; ++k) {
                int d = d_start + i;
                int h = h_start + j;
                int w = w_start + k;
                
                if(d < D && h < H && w < W) {
                    int input_idx = b * C * D * H * W 
                                  + c * D * H * W 
                                  + d * H * W 
                                  + h * W 
                                  + w;
                    sum += input[input_idx] * scale1;
                }
            }
        }
    }

    float average = sum / 8.0f;
    float result = (average + bias[c]) * scale2;

    // Calculate output index
    int output_idx = b * C * D_pool * H_pool * W_pool
                   + c * D_pool * H_pool * W_pool
                   + d_pool * H_pool * W_pool
                   + h_pool * W_pool
                   + w_pool;
    
    output[output_idx] = result;
}

torch::Tensor fused_scale_pool_bias_scale_cuda(
    torch::Tensor input,
    float scale1,
    torch::Tensor bias,
    float scale2
) {
    auto sizes = input.sizes();
    int B = sizes[0], C = sizes[1], D = sizes[2], H = sizes[3], W = sizes[4];
    int D_pool = D / 2, H_pool = H / 2, W_pool = W / 2;
    
    auto output = torch::zeros({B, C, D_pool, H_pool, W_pool}, input.options());
    int total_elements = B * C * D_pool * H_pool * W_pool;
    
    const int block_size = 256;
    int grid_size = (total_elements + block_size - 1) / block_size;
    
    fused_scale_pool_bias_scale_kernel<<<grid_size, block_size>>>(
        input.data_ptr<float>(),
        bias.data_ptr<float>(),
        scale1,
        scale2,
        output.data_ptr<float>(),
        B, C, D, H, W
    );
    
    return output;
}
"""

fused_op_cpp_source = "torch::Tensor fused_scale_pool_bias_scale_cuda(torch::Tensor input, float scale1, torch::Tensor bias, float scale2);"

fused_op = load_inline(
    name='fused_op',
    cpp_sources=fused_op_cpp_source,
    cuda_sources=fused_op_source,
    functions=['fused_scale_pool_bias_scale_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size, stride=stride, padding=padding
        )
        self.scale1 = nn.Parameter(torch.tensor(scale1))
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.scale2 = nn.Parameter(torch.tensor(scale2))

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_op.fused_scale_pool_bias_scale_cuda(
            x, 
            self.scale1.item(), 
            self.bias, 
            self.scale2.item()
        )
        return x
```

Kernel 2 (runtime: 23.3 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

fused_kernel_code = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

template<typename T>
__global__ void fused_op_kernel(
    const T* input,
    T* output,
    const T* bias,
    int N, int C, int D_in, int H_in, int W_in,
    int D_out, int H_out, int W_out,
    T scale1,
    T scale2) {

    int total_elements = N * C * D_out * H_out * W_out;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= total_elements) return;

    int w = idx % W_out;
    int h = (idx / W_out) % H_out;
    int d = (idx / (W_out * H_out)) % D_out;
    int c = (idx / (W_out * H_out * D_out)) % C;
    int n = idx / (W_out * H_out * D_out * C);

    T sum = static_cast<T>(0);
    for(int dd=0; dd<2; ++dd){
        for(int hh=0; hh<2; ++hh){
            for(int ww=0; ww<2; ++ww){
                int d_in = d * 2 + dd;
                int h_in = h * 2 + hh;
                int w_in = w * 2 + ww;
                
                int in_idx = n*C*D_in*H_in*W_in +
                            c*D_in*H_in*W_in +
                            d_in*H_in*W_in +
                            h_in*W_in + w_in;
                            
                sum += input[in_idx];
            }
        }
    }

    T val = (sum * scale1) / static_cast<T>(8);
    val += bias[c];
    val *= scale2;
    output[idx] = val;
}

torch::Tensor fused_forward(
    torch::Tensor input,
    torch::Tensor bias,
    float scale1,
    float scale2) {

    // Ensure input is contiguous
    input = input.contiguous();

    // Compute output dimensions
    int N = input.size(0);
    int C = input.size(1);
    int D_in = input.size(2);
    int H_in = input.size(3);
    int W_in = input.size(4);

    int D_out = D_in / 2;
    int H_out = H_in / 2;
    int W_out = W_in / 2;

    auto output = torch::empty({N, C, D_out, H_out, W_out}, input.options());

    // Launch kernel
    int total_elements = N * C * D_out * H_out * W_out;
    dim3 blocks((total_elements + 255)/256);
    dim3 threads(256);

    AT_DISPATCH_FLOATING_TYPES(input.scalar_type(), "fused_forward", ([&] {
        fused_op_kernel<scalar_t><<<blocks, threads>>>(
            input.data_ptr<scalar_t>(),
            output.data_ptr<scalar_t>(),
            bias.data_ptr<scalar_t>(),
            N, C, D_in, H_in, W_in,
            D_out, H_out, W_out,
            scale1,
            scale2);
    }));

    return output;
}
"""

cpp_wrapper = "torch::Tensor fused_forward(torch::Tensor input, torch::Tensor bias, float scale1, float scale2);"

fused_ext = load_inline(
    name='fused_ext',
    cpp_sources=cpp_wrapper,
    cuda_sources=fused_kernel_code,
    functions=['fused_forward'],
    verbose=False
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.scale1 = nn.Parameter(torch.tensor(scale1))
        self.scale2 = nn.Parameter(torch.tensor(scale2))

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_ext.fused_forward(x, self.bias, self.scale1.item(), self.scale2.item())
        return x
```
