You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 15.3 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Optimized CUDA kernel for 3D global average pooling with coalesced memory access
pool_kernel_source = '''
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void global_pool_kernel(const float* input, float* output, 
                                  int B, int C, int D, int H, int W) {
    extern __shared__ float shared[];
    
    int bid = blockIdx.x;  // Each block handles one (batch, channel) pair
    int c = bid % C;
    int b = bid / C;
    
    int elements = D * H * W;
    int tid = threadIdx.x;
    int elements_per_thread = (elements + blockDim.x - 1) / blockDim.x;
    int start = tid * elements_per_thread;
    int end = min(start + elements_per_thread, elements);
    
    float sum = 0.0f;
    
    // Coalesced memory access pattern
    for(int i = start; i < end; ++i) {
        int d = i / (H * W);
        int rem = i % (H * W);
        int h = rem / W;
        int w = rem % W;
        int idx = b*C*D*H*W + c*D*H*W + d*H*W + h*W + w;
        sum += input[idx];
    }
    
    shared[tid] = sum;
    __syncthreads();
    
    // Optimized tree reduction
    for(int stride = blockDim.x/2; stride > 0; stride >>= 1) {
        if(tid < stride) {
            shared[tid] += shared[tid + stride];
        }
        __syncthreads();
    }
    
    if(tid == 0) {
        output[b*C + c] = shared[0] / elements;
    }
}

torch::Tensor global_avg_pool(torch::Tensor x) {
    auto sizes = x.sizes();
    int B = sizes[0], C = sizes[1], D = sizes[2], H = sizes[3], W = sizes[4];
    auto output = torch::zeros({B, C, 1, 1, 1}, x.options());
    
    dim3 grid(B*C);
    int block_size = 256;
    dim3 block(block_size);
    
    global_pool_kernel<<<grid, block, block_size*sizeof(float)>>>(
        x.data_ptr<float>(),
        output.data_ptr<float>(),
        B, C, D, H, W
    );
    
    return output;
}
'''

pool_cpp_source = "torch::Tensor global_avg_pool(torch::Tensor x);"

custom_pool = load_inline(
    name='custom_pool',
    cpp_sources=pool_cpp_source,
    cuda_sources=pool_kernel_source,
    functions=['global_avg_pool'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):
        super().__init__()
        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)
        
        # Fuse scale factor into convolution weights
        with torch.no_grad():
            self.conv_transpose.weight.data *= scale_factor
            if self.conv_transpose.bias is not None:
                self.conv_transpose.bias.data *= scale_factor
                
        self.bn = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)
        self.pool = custom_pool.global_avg_pool

    def forward(self, x):
        x = self.conv_transpose(x)
        x = self.bn(x)
        x = self.pool(x.contiguous())  # Ensure contiguous memory for kernel
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width).cuda()]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, scale_factor]

batch_size = 16
in_channels = 64
out_channels = 128
depth, height, width = 16, 32, 32
kernel_size = 5
scale_factor = 2.0
```

Kernel 2 (runtime: 14.4 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for optimized 3D global average pooling
pool_kernel_source = '''
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void global_pool_kernel(const float* input, float* output, 
                                  int B, int C, int D, int H, int W) {
    int bid = blockIdx.x;
    int c = bid % C;
    int b = bid / C;
    
    int elements = D * H * W;
    float sum = 0.0f;
    
    for(int i = threadIdx.x; i < elements; i += blockDim.x) {
        int d = i / (H * W);
        int h = (i % (H * W)) / W;
        int w = i % W;
        int idx = b*C*D*H*W + c*D*H*W + d*H*W + h*W + w;
        sum += input[idx];
    }
    
    __shared__ float shared[256];
    shared[threadIdx.x] = sum;
    __syncthreads();
    
    // Reduction
    for(int stride=128; stride>0; stride>>=1) {
        if(threadIdx.x < stride) {
            shared[threadIdx.x] += shared[threadIdx.x + stride];
        }
        __syncthreads();
    }
    
    if(threadIdx.x == 0) {
        output[b*C + c] = shared[0] / elements;
    }
}

torch::Tensor global_avg_pool(torch::Tensor x) {
    auto sizes = x.sizes();
    int B = sizes[0], C = sizes[1], D = sizes[2], H = sizes[3], W = sizes[4];
    auto output = torch::zeros({B, C, 1, 1, 1}, x.options());
    
    dim3 grid(B*C);
    dim3 block(256);
    
    global_pool_kernel<<<grid, block>>>(
        x.data_ptr<float>(),
        output.data_ptr<float>(),
        B, C, D, H, W
    );
    
    return output;
}
'''

pool_cpp_source = "torch::Tensor global_avg_pool(torch::Tensor x);"

custom_pool = load_inline(
    name='custom_pool',
    cpp_sources=pool_cpp_source,
    cuda_sources=pool_kernel_source,
    functions=['global_avg_pool'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):
        super().__init__()
        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)
        
        # Fuse scale factor into convolution weights
        with torch.no_grad():
            self.conv_transpose.weight.data *= scale_factor
            if self.conv_transpose.bias is not None:
                self.conv_transpose.bias.data *= scale_factor
                
        self.bn = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)
        self.pool = custom_pool.global_avg_pool

    def forward(self, x):
        x = self.conv_transpose(x)
        x = self.bn(x)
        x = self.pool(x.contiguous())  # Ensure contiguous memory for kernel
        return x

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width).cuda()]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, scale_factor]

batch_size = 16
in_channels = 64
out_channels = 128
depth, height, width = 16, 32, 32
kernel_size = 5
scale_factor = 2.0
```
