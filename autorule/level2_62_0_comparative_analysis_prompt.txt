You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 7.58 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define the fused GroupNorm + LeakyReLU + Scale CUDA kernel
fused_groupnorm_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void fused_groupnorm_lrelu_scale_kernel(
    const float* input,
    const float* gamma,
    const float* beta,
    float* output,
    int hidden_size,
    int num_groups,
    float eps,
    float negative_slope) {

    extern __shared__ float shmem[];
    float* sh_data = shmem;

    int group_size = hidden_size / num_groups;
    int batch_idx = blockIdx.x / num_groups;
    int group_idx = blockIdx.x % num_groups;

    int start_input = batch_idx * hidden_size + group_idx * group_size;
    int tid = threadIdx.x;

    // Load data into shared memory
    if (tid < group_size) {
        sh_data[tid] = input[start_input + tid];
    }
    __syncthreads();

    // Compute sum and sum of squares
    float sum = 0.0f;
    float sum_sq = 0.0f;
    for (int i = 0; i < group_size; ++i) {
        float val = sh_data[i];
        sum += val;
        sum_sq += val * val;
    }

    float mean = sum / group_size;
    float var = sum_sq / group_size - mean * mean;
    float inv_std = rsqrtf(var + eps);

    // Apply normalization, LeakyReLU, and scaling
    if (tid < group_size) {
        float x = sh_data[tid];
        int channel_idx = group_idx * group_size + tid;
        float gamma_val = gamma[channel_idx];
        float beta_val = beta[channel_idx];

        float normalized = (x - mean) * inv_std * gamma_val + beta_val;
        float lrelu = (normalized > 0) ? normalized : normalized * negative_slope;
        float scaled = lrelu * 2.0f;
        output[start_input + tid] = scaled;
    }
}

torch::Tensor fused_groupnorm_lrelu_scale_cuda(
    torch::Tensor input,
    torch::Tensor gamma,
    torch::Tensor beta,
    int num_groups,
    float eps,
    float negative_slope) {

    auto output = torch::zeros_like(input);
    int batch_size = input.size(0);
    int hidden_size = input.size(1);
    int group_size = hidden_size / num_groups;

    if (hidden_size % num_groups != 0) {
        throw std::invalid_argument("hidden_size must be divisible by num_groups");
    }

    dim3 grid(batch_size * num_groups);
    dim3 block(group_size);

    size_t shared_mem_size = group_size * sizeof(float);

    fused_groupnorm_lrelu_scale_kernel<<<grid, block, shared_mem_size>>>(
        input.data_ptr<float>(),
        gamma.data_ptr<float>(),
        beta.data_ptr<float>(),
        output.data_ptr<float>(),
        hidden_size,
        num_groups,
        eps,
        negative_slope);

    return output;
}
"""

fused_groupnorm_cpp_source = """
torch::Tensor fused_groupnorm_lrelu_scale_cuda(
    torch::Tensor input,
    torch::Tensor gamma,
    torch::Tensor beta,
    int num_groups,
    float eps,
    float negative_slope);
"""

# Compile the inline CUDA code
fused_groupnorm = load_inline(
    name='fused_groupnorm',
    cpp_sources=fused_groupnorm_cpp_source,
    cuda_sources=fused_groupnorm_source,
    functions=['fused_groupnorm_lrelu_scale_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[],
)

class ModelNew(nn.Module):
    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):
        super().__init__()
        self.fc = nn.Linear(input_size, hidden_size)
        self.num_groups = num_groups
        self.hidden_size = hidden_size
        self.eps = eps
        self.negative_slope = negative_slope
        self.gamma = nn.Parameter(torch.ones(hidden_size))
        self.beta = nn.Parameter(torch.zeros(hidden_size))

    def forward(self, x):
        x = self.fc(x)
        x = fused_groupnorm.fused_groupnorm_lrelu_scale_cuda(
            x, 
            self.gamma, 
            self.beta,
            self.num_groups,
            self.eps,
            self.negative_slope
        )
        return x
```

Kernel 2 (runtime: 7.59 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for fused GroupNorm + LeakyReLU + Scale
fused_kernel_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <cmath>

__global__ void fused_groupnorm_leaky_relu_scale_kernel(
    const float* input,
    const float* weight,
    const float* bias,
    float* output,
    int hidden_size,
    int num_groups,
    float eps,
    float negative_slope,
    float scale_factor) {

    extern __shared__ float shared[];

    int batch_idx = blockIdx.x / num_groups;
    int group_idx = blockIdx.x % num_groups;

    int channels_per_group = hidden_size / num_groups;
    int channel_idx = group_idx * channels_per_group + threadIdx.x;

    int input_idx = batch_idx * hidden_size + channel_idx;

    float x = input[input_idx];

    // Store in shared memory for sum and sum of squares
    shared[threadIdx.x] = x;
    shared[threadIdx.x + blockDim.x] = x * x;

    __syncthreads();

    // Tree reduction for sum and sum_sq
    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (threadIdx.x < stride) {
            shared[threadIdx.x] += shared[threadIdx.x + stride];
            shared[threadIdx.x + blockDim.x] += shared[threadIdx.x + stride + blockDim.x];
        }
        __syncthreads();
    }

    float sum = shared[0];
    float sum_sq = shared[blockDim.x];

    float mean = sum / channels_per_group;
    float var = (sum_sq / channels_per_group) - (mean * mean);

    // Normalize
    float normalized = (x - mean) / sqrt(var + eps);

    // Apply scale and bias
    float scale = weight[channel_idx];
    float shift = bias[channel_idx];
    float result = normalized * scale + shift;

    // Leaky ReLU
    result = (result > 0) ? result : result * negative_slope;

    // Scale by scale_factor (2.0)
    result *= scale_factor;

    output[input_idx] = result;
}

torch::Tensor fused_gn_leaky_relu_scale_cuda(
    torch::Tensor input,
    torch::Tensor weight,
    torch::Tensor bias,
    int hidden_size,
    int num_groups,
    float eps,
    float negative_slope,
    float scale_factor) {

    auto output = torch::empty_like(input);
    int batch_size = input.size(0);
    int channels_per_group = hidden_size / num_groups;

    if (hidden_size % num_groups != 0) {
        throw std::invalid_argument("hidden_size must be divisible by num_groups");
    }

    dim3 blocks(batch_size * num_groups);
    dim3 threads(channels_per_group);

    size_t shared_mem_size = 2 * channels_per_group * sizeof(float);

    fused_groupnorm_leaky_relu_scale_kernel<<<blocks, threads, shared_mem_size>>>(
        input.data_ptr<float>(),
        weight.data_ptr<float>(),
        bias.data_ptr<float>(),
        output.data_ptr<float>(),
        hidden_size,
        num_groups,
        eps,
        negative_slope,
        scale_factor
    );

    return output;
}
"""

fused_kernel_cpp = """
torch::Tensor fused_gn_leaky_relu_scale_cuda(
    torch::Tensor input,
    torch::Tensor weight,
    torch::Tensor bias,
    int hidden_size,
    int num_groups,
    float eps,
    float negative_slope,
    float scale_factor);
"""

# Load the inline CUDA extension
fused_gn_relu_scale = load_inline(
    name='fused_gn_relu_scale',
    cpp_sources=fused_kernel_cpp,
    cuda_sources=fused_kernel_source,
    functions=['fused_gn_leaky_relu_scale_cuda'],
    verbose=True,
    extra_cflags=['-O3'],
    extra_ldflags=[],
)

class ModelNew(nn.Module):
    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):
        super(ModelNew, self).__init__()
        self.fc = nn.Linear(input_size, hidden_size)
        self.hidden_size = hidden_size
        self.num_groups = num_groups
        self.eps = eps
        self.negative_slope = negative_slope
        
        # Initialize GroupNorm parameters
        self.gn_weight = nn.Parameter(torch.ones(hidden_size))
        self.gn_bias = nn.Parameter(torch.zeros(hidden_size))

    def forward(self, x):
        x = self.fc(x)
        x = fused_gn_relu_scale.fused_gn_leaky_relu_scale_cuda(
            x,
            self.gn_weight,
            self.gn_bias,
            self.hidden_size,
            self.num_groups,
            self.eps,
            self.negative_slope,
            2.0  # Scale factor for x + x operation
        )
        return x
```
