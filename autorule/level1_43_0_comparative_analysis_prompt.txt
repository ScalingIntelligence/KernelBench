You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 6.82 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

maxpool3d_cuda_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <cfloat>

__global__ void max_pool3d_kernel(
    const float* __restrict__ input,
    float* __restrict__ output,
    const int batch_size,
    const int channels,
    const int input_d, const int input_h, const int input_w,
    const int input_hw, const int input_dhw,
    const int output_d, const int output_h, const int output_w,
    const int output_hw, const int output_dhw, const int channels_dhw,
    const int kernel_d, const int kernel_h, const int kernel_w,
    const int stride_d, const int stride_h, const int stride_w,
    const int padding_d, const int padding_h, const int padding_w,
    const int dilation_d, const int dilation_h, const int dilation_w
) {
    const int total_elements = batch_size * channels * output_d * output_h * output_w;
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int stride = blockDim.x * gridDim.x;
    
    for (int idx = tid; idx < total_elements; idx += stride) {
        // Optimized index calculation using fused dimensions
        const int b = idx / channels_dhw;
        const int c = (idx % channels_dhw) / output_dhw;
        const int odhw = idx % output_dhw;
        const int od = odhw / output_hw;
        const int ohw = odhw % output_hw;
        const int oh = ohw / output_w;
        const int ow = ohw % output_w;

        const int start_d = od * stride_d - padding_d;
        const int start_h = oh * stride_h - padding_h;
        const int start_w = ow * stride_w - padding_w;

        // Precompute valid kernel ranges
        int kd_min = max(0, (-start_d + dilation_d - 1) / dilation_d);
        int kd_max = min(kernel_d - 1, (input_d - start_d - 1) / dilation_d);
        if (kd_min > kd_max) continue;

        int kh_min = max(0, (-start_h + dilation_h - 1) / dilation_h);
        int kh_max = min(kernel_h - 1, (input_h - start_h - 1) / dilation_h);
        if (kh_min > kh_max) continue;

        int kw_min = max(0, (-start_w + dilation_w - 1) / dilation_w);
        int kw_max = min(kernel_w - 1, (input_w - start_w - 1) / dilation_w);
        if (kw_min > kw_max) continue;

        const int bc_offset = (b * channels + c) * input_dhw;
        float max_val = -FLT_MAX;

        // Optimized loops with precomputed ranges
        for (int kd = kd_min; kd <= kd_max; ++kd) {
            const int id = start_d + kd * dilation_d;
            const int id_offset = id * input_hw;
            
            for (int kh = kh_min; kh <= kh_max; ++kh) {
                const int ih = start_h + kh * dilation_h;
                const int ih_offset = ih * input_w;
                
                for (int kw = kw_min; kw <= kw_max; ++kw) {
                    const int iw = start_w + kw * dilation_w;
                    const int input_idx = bc_offset + id_offset + ih_offset + iw;
                    max_val = fmaxf(max_val, __ldg(&input[input_idx]));
                }
            }
        }
        output[idx] = max_val;
    }
}

torch::Tensor max_pool3d_cuda(
    torch::Tensor input,
    int kernel_size,
    int stride,
    int padding,
    int dilation,
    bool ceil_mode
) {
    // Parameter expansion for 3D
    const int kernel_d = kernel_size, kernel_h = kernel_size, kernel_w = kernel_size;
    const int stride_d = stride, stride_h = stride, stride_w = stride;
    const int padding_d = padding, padding_h = padding, padding_w = padding;
    const int dilation_d = dilation, dilation_h = dilation, dilation_w = dilation;

    // Input dimensions
    const int batch_size = input.size(0);
    const int channels = input.size(1);
    const int input_d = input.size(2);
    const int input_h = input.size(3);
    const int input_w = input.size(4);
    const int input_hw = input_h * input_w;
    const int input_dhw = input_d * input_hw;

    // Output dimension calculation
    auto compute_output_size = [](int input_size, int kernel, int stride, int pad, int dil, bool ceil) {
        const int effective_kernel = dil * (kernel - 1) + 1;
        int numerator = input_size + 2 * pad - effective_kernel;
        if (numerator < 0) numerator = 0;
        
        int output_size;
        if (ceil) {
            output_size = (numerator + stride - 1) / stride + 1;
            if ((output_size - 1) * stride >= input_size + pad) --output_size;
        } else {
            output_size = numerator / stride + 1;
        }
        return output_size;
    };

    const int output_d = compute_output_size(input_d, kernel_size, stride, padding, dilation, ceil_mode);
    const int output_h = compute_output_size(input_h, kernel_size, stride, padding, dilation, ceil_mode);
    const int output_w = compute_output_size(input_w, kernel_size, stride, padding, dilation, ceil_mode);
    const int output_hw = output_h * output_w;
    const int output_dhw = output_d * output_hw;
    const int channels_dhw = channels * output_dhw;

    auto output = torch::empty({batch_size, channels, output_d, output_h, output_w}, input.options());

    const int total_elements = output.numel();
    const int threads = 512;  // Increased thread count for better occupancy
    const int max_blocks = 65535;
    const int blocks = min((total_elements + threads - 1) / threads, max_blocks);

    max_pool3d_kernel<<<blocks, threads>>>(
        input.contiguous().data_ptr<float>(),
        output.contiguous().data_ptr<float>(),
        batch_size,
        channels,
        input_d, input_h, input_w,
        input_hw, input_dhw,
        output_d, output_h, output_w,
        output_hw, output_dhw, channels_dhw,
        kernel_d, kernel_h, kernel_w,
        stride_d, stride_h, stride_w,
        padding_d, padding_h, padding_w,
        dilation_d, dilation_h, dilation_w
    );

    return output;
}
"""

maxpool3d_cpp_source = """
torch::Tensor max_pool3d_cuda(
    torch::Tensor input,
    int kernel_size,
    int stride,
    int padding,
    int dilation,
    bool ceil_mode
);
"""

maxpool3d_ext = load_inline(
    name='maxpool3d_ext',
    cpp_sources=maxpool3d_cpp_source,
    cuda_sources=maxpool3d_cuda_source,
    functions=['max_pool3d_cuda'],
    verbose=True
)

class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, 
                 dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):
        super().__init__()
        if stride is None:
            stride = kernel_size
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.ceil_mode = ceil_mode
        self.return_indices = return_indices

    def forward(self, x):
        if self.return_indices:
            raise NotImplementedError("Returning indices not supported in custom implementation")
        return maxpool3d_ext.max_pool3d_cuda(
            x,
            self.kernel_size,
            self.stride,
            self.padding,
            self.dilation,
            self.ceil_mode
        )
```

Kernel 2 (runtime: 7.05 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

max_pool_3d_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

__global__ void max_pool_3d_kernel(
    const float* __restrict__ input,
    float* __restrict__ output,
    const int batch_size,
    const int channels,
    const int in_d1, const int in_d2, const int in_d3,
    const int out_d1, const int out_d2, const int out_d3,
    const int kernel_size,
    const int stride,
    const int padding,
    const int dilation,
    const bool ceil_mode
) {
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int total_elements = batch_size * channels * out_d1 * out_d2 * out_d3;
    if (tid >= total_elements) return;

    const int n = tid / (channels * out_d1 * out_d2 * out_d3);
    const int c = (tid / (out_d1 * out_d2 * out_d3)) % channels;
    const int d1_out = (tid / (out_d2 * out_d3)) % out_d1;
    const int d2_out = (tid / out_d3) % out_d2;
    const int d3_out = tid % out_d3;

    const int stride_d = stride;
    const int padding_d = padding;
    const int dilation_d = dilation;

    float max_val = -INFINITY;

    for (int kd = 0; kd < kernel_size; ++kd) {
        const int d_in = d1_out * stride_d + kd * dilation_d - padding_d;
        if (d_in < 0 || d_in >= in_d1) continue;

        for (int ld = 0; ld < kernel_size; ++ld) {
            const int d2_in = d2_out * stride_d + ld * dilation_d - padding_d;
            if (d2_in < 0 || d2_in >= in_d2) continue;

            for (int md = 0; md < kernel_size; ++md) {
                const int d3_in = d3_out * stride_d + md * dilation_d - padding_d;
                if (d3_in < 0 || d3_in >= in_d3) continue;

                const int offset = ((n * channels + c) * in_d1 + d_in) * in_d2 * in_d3 + d2_in * in_d3 + d3_in;
                max_val = fmaxf(max_val, input[offset]);
            }
        }
    }

    const int output_offset = ((n * channels + c) * out_d1 + d1_out) * out_d2 * out_d3 + d2_out * out_d3 + d3_out;
    output[output_offset] = max_val;
}

torch::Tensor max_pool_3d_cuda_forward(
    torch::Tensor input,
    int kernel_size,
    int stride,
    int padding,
    int dilation,
    bool ceil_mode
) {
    TORCH_CHECK(input.is_contiguous(), "Input must be contiguous");
    TORCH_CHECK(input.dim() == 5, "Input must be 5D");

    const auto sizes = input.sizes();
    const int N = sizes[0], C = sizes[1],
              D1 = sizes[2], D2 = sizes[3], D3 = sizes[4];

    const int D1_out = ceil_mode
        ? (D1 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1
        : (D1 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1;

    const int D2_out = ceil_mode
        ? (D2 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1
        : (D2 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1;

    const int D3_out = ceil_mode
        ? (D3 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1
        : (D3 + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1;

    auto output = torch::empty({N, C, D1_out, D2_out, D3_out}, input.options());

    const int total_elements = N * C * D1_out * D2_out * D3_out;
    const int threads_per_block = 256;
    const int blocks_per_grid = (total_elements + threads_per_block - 1) / threads_per_block;

    max_pool_3d_kernel<<<blocks_per_grid, threads_per_block>>>(
        input.data_ptr<float>(),
        output.data_ptr<float>(),
        N, C,
        D1, D2, D3,
        D1_out, D2_out, D3_out,
        kernel_size,
        stride,
        padding,
        dilation,
        ceil_mode
    );

    return output;
}
"""

max_pool_3d_cpp_header = "torch::Tensor max_pool_3d_cuda_forward(torch::Tensor input, int kernel_size, int stride, int padding, int dilation, bool ceil_mode);"

max_pool_3d_ext = load_inline(
    name='max_pool_3d',
    cpp_sources=max_pool_3d_cpp_header,
    cuda_sources=max_pool_3d_source,
    functions=['max_pool_3d_cuda_forward'],
    verbose=True,
    extra_cflags=[],
    extra_ldflags=[]
)

class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, ceil_mode: bool = False):
        super().__init__()
        self.kernel_size = kernel_size
        self.stride = stride if stride is not None else kernel_size
        self.padding = padding
        self.dilation = dilation
        self.ceil_mode = ceil_mode

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return max_pool_3d_ext.max_pool_3d_cuda_forward(
            x.contiguous(),
            self.kernel_size,
            self.stride,
            self.padding,
            self.dilation,
            self.ceil_mode
        )
```
