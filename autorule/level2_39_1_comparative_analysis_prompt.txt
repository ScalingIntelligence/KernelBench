You are a kernel expert. You are given two CUDA kernels that solve the same problem. Both kernels are correct, but one is faster than the other. Analyze why one is faster than the other.
Kernel 1 (runtime: 30.7 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Optimized fused scale + batch norm kernel with vectorized loads and read-only cache
fused_scale_bn_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

#define UNROLL_FACTOR 8
#define LAUNCH_BOUNDS 256

__global__ void __launch_bounds__(LAUNCH_BOUNDS) fused_scale_bn_kernel(
    const float* __restrict__ input,
    const float* __restrict__ scale,
    const float* __restrict__ gamma,
    const float* __restrict__ beta,
    float* __restrict__ running_mean,
    float* __restrict__ running_var,
    float* __restrict__ output,
    int batch_size,
    int num_features,
    float eps,
    float momentum,
    bool training) {

    const int feature_idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (feature_idx >= num_features) return;

    const float s = scale[feature_idx];
    const float g = gamma[feature_idx];
    const float b = beta[feature_idx];

    // Phase 1: Compute sum and sum_sq with read-only cache
    float sum = 0.0f, sum_sq = 0.0f;
    int i = 0;

    // Process unrolled chunks with __ldg for read-only cache
    for (; i <= batch_size - UNROLL_FACTOR; i += UNROLL_FACTOR) {
        #pragma unroll
        for (int j = 0; j < UNROLL_FACTOR; j++) {
            float val = __ldg(&input[(i+j)*num_features + feature_idx]) * s;
            sum += val;
            sum_sq += val * val;
        }
    }

    // Process remaining elements
    for (; i < batch_size; ++i) {
        float val = __ldg(&input[i*num_features + feature_idx]) * s;
        sum += val;
        sum_sq += val * val;
    }

    // Compute statistics with numerical stability
    float mean = sum / batch_size;
    float var = (sum_sq / batch_size) - (mean * mean);
    var = fmaxf(var, 0.0f);

    if (training) {
        // Update running statistics using Welford's algorithm
        running_mean[feature_idx] = (1 - momentum) * running_mean[feature_idx] + momentum * mean;
        running_var[feature_idx] = (1 - momentum) * running_var[feature_idx] + momentum * var;
    } else {
        mean = running_mean[feature_idx];
        var = running_var[feature_idx];
    }

    // Precompute normalization factors
    const float inv_std = rsqrtf(var + eps);
    const float scale_g = inv_std * g;
    const float shift = b - mean * scale_g;

    // Phase 2: Apply transformation with vectorized stores
    i = 0;
    for (; i <= batch_size - UNROLL_FACTOR; i += UNROLL_FACTOR) {
        #pragma unroll
        for (int j = 0; j < UNROLL_FACTOR; j++) {
            float val = __ldg(&input[(i+j)*num_features + feature_idx]) * s;
            output[(i+j)*num_features + feature_idx] = val * scale_g + shift;
        }
    }

    // Process remaining elements
    for (; i < batch_size; ++i) {
        float val = __ldg(&input[i*num_features + feature_idx]) * s;
        output[i*num_features + feature_idx] = val * scale_g + shift;
    }
}

torch::Tensor fused_scale_bn_cuda(
    torch::Tensor input,
    torch::Tensor scale,
    torch::Tensor gamma,
    torch::Tensor beta,
    torch::Tensor running_mean,
    torch::Tensor running_var,
    float eps,
    float momentum,
    bool training) {

    auto batch_size = input.size(0);
    auto num_features = input.size(1);
    auto output = torch::empty_like(input);

    const int block_size = LAUNCH_BOUNDS;
    const int grid_size = (num_features + block_size - 1) / block_size;

    fused_scale_bn_kernel<<<grid_size, block_size>>>(
        input.data_ptr<float>(),
        scale.data_ptr<float>(),
        gamma.data_ptr<float>(),
        beta.data_ptr<float>(),
        running_mean.data_ptr<float>(),
        running_var.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size,
        num_features,
        eps,
        momentum,
        training
    );

    return output;
}
"""

fused_scale_bn_cpp_source = """
torch::Tensor fused_scale_bn_cuda(
    torch::Tensor input,
    torch::Tensor scale,
    torch::Tensor gamma,
    torch::Tensor beta,
    torch::Tensor running_mean,
    torch::Tensor running_var,
    float eps,
    float momentum,
    bool training);
"""

# Load the optimized CUDA extension
fused_scale_bn = load_inline(
    name='fused_scale_bn',
    cpp_sources=fused_scale_bn_cpp_source,
    cuda_sources=fused_scale_bn_source,
    functions=['fused_scale_bn_cuda'],
    verbose=True,
    extra_cuda_cflags=['-O3', '--use_fast_math', '-Xptxas=-v']
)

class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):
        super().__init__()
        self.gemm = nn.Linear(in_features, out_features)
        self.scale = nn.Parameter(torch.randn(scale_shape))
        
        # BN parameters
        self.gamma = nn.Parameter(torch.ones(out_features))
        self.beta = nn.Parameter(torch.zeros(out_features))
        
        # BN buffers
        self.register_buffer('running_mean', torch.zeros(out_features))
        self.register_buffer('running_var', torch.ones(out_features))
        
        self.eps = eps
        self.momentum = momentum

    def forward(self, x):
        x = self.gemm(x)
        x = fused_scale_bn.fused_scale_bn_cuda(
            x, 
            self.scale, 
            self.gamma,
            self.beta,
            self.running_mean,
            self.running_var,
            self.eps,
            self.momentum,
            self.training
        )
        return x
```

Kernel 2 (runtime: 30.6 ms):
```
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Optimized fused scale + batch norm kernel with coalesced access and fast math
fused_scale_bn_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>
#include <cuda_fp16.h>

__global__ void fused_scale_bn_kernel(
    const float* __restrict__ input,
    const float* __restrict__ scale,
    const float* __restrict__ gamma,
    const float* __restrict__ beta,
    float* __restrict__ running_mean,
    float* __restrict__ running_var,
    float* __restrict__ output,
    int batch_size,
    int num_features,
    float eps,
    float momentum,
    bool training) {

    const int feature_idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (feature_idx >= num_features) return;

    const float s = scale[feature_idx];
    const float g = gamma[feature_idx];
    const float b = beta[feature_idx];

    // Phase 1: Compute sum and sum_sq with vectorized loads
    float sum = 0.0f, sum_sq = 0.0f;
    const int unroll = 4;
    int i = 0;

    // Process unrolled chunks
    for (; i <= batch_size - unroll; i += unroll) {
        #pragma unroll
        for (int j = 0; j < unroll; j++) {
            float val = input[(i+j)*num_features + feature_idx] * s;
            sum += val;
            sum_sq += val * val;
        }
    }

    // Process remaining elements
    for (; i < batch_size; ++i) {
        float val = input[i*num_features + feature_idx] * s;
        sum += val;
        sum_sq += val * val;
    }

    // Compute statistics
    float mean = sum / batch_size;
    float var = (sum_sq / batch_size) - (mean * mean);
    var = max(var, 0.0f);  // Numerical stability

    if (training) {
        // Update running statistics
        running_mean[feature_idx] = (1 - momentum) * running_mean[feature_idx] + momentum * mean;
        running_var[feature_idx] = (1 - momentum) * running_var[feature_idx] + momentum * var;
    } else {
        mean = running_mean[feature_idx];
        var = running_var[feature_idx];
    }

    // Precompute normalization factors
    const float inv_std = rsqrtf(var + eps);
    const float scale_g = inv_std * g;
    const float shift = b - mean * scale_g;

    // Phase 2: Apply transformation with vectorized stores
    i = 0;
    for (; i <= batch_size - unroll; i += unroll) {
        #pragma unroll
        for (int j = 0; j < unroll; j++) {
            float val = input[(i+j)*num_features + feature_idx] * s;
            output[(i+j)*num_features + feature_idx] = val * scale_g + shift;
        }
    }

    // Process remaining elements
    for (; i < batch_size; ++i) {
        float val = input[i*num_features + feature_idx] * s;
        output[i*num_features + feature_idx] = val * scale_g + shift;
    }
}

torch::Tensor fused_scale_bn_cuda(
    torch::Tensor input,
    torch::Tensor scale,
    torch::Tensor gamma,
    torch::Tensor beta,
    torch::Tensor running_mean,
    torch::Tensor running_var,
    float eps,
    float momentum,
    bool training) {

    auto batch_size = input.size(0);
    auto num_features = input.size(1);
    auto output = torch::empty_like(input);

    const int block_size = 256;
    const int grid_size = (num_features + block_size - 1) / block_size;

    fused_scale_bn_kernel<<<grid_size, block_size>>>(
        input.data_ptr<float>(),
        scale.data_ptr<float>(),
        gamma.data_ptr<float>(),
        beta.data_ptr<float>(),
        running_mean.data_ptr<float>(),
        running_var.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size,
        num_features,
        eps,
        momentum,
        training
    );

    return output;
}
"""

fused_scale_bn_cpp_source = """
torch::Tensor fused_scale_bn_cuda(
    torch::Tensor input,
    torch::Tensor scale,
    torch::Tensor gamma,
    torch::Tensor beta,
    torch::Tensor running_mean,
    torch::Tensor running_var,
    float eps,
    float momentum,
    bool training);
"""

# Load the optimized CUDA extension
fused_scale_bn = load_inline(
    name='fused_scale_bn',
    cpp_sources=fused_scale_bn_cpp_source,
    cuda_sources=fused_scale_bn_source,
    functions=['fused_scale_bn_cuda'],
    verbose=True,
    extra_cuda_cflags=['-O3', '--use_fast_math', '-Xptxas=-v']
)

class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):
        super().__init__()
        self.gemm = nn.Linear(in_features, out_features)
        self.scale = nn.Parameter(torch.randn(scale_shape))
        
        # BN parameters
        self.gamma = nn.Parameter(torch.ones(out_features))
        self.beta = nn.Parameter(torch.zeros(out_features))
        
        # BN buffers
        self.register_buffer('running_mean', torch.zeros(out_features))
        self.register_buffer('running_var', torch.ones(out_features))
        
        self.eps = eps
        self.momentum = momentum

    def forward(self, x):
        x = self.gemm(x)
        x = fused_scale_bn.fused_scale_bn_cuda(
            x, 
            self.scale, 
            self.gamma,
            self.beta,
            self.running_mean,
            self.running_var,
            self.eps,
            self.momentum,
            self.training
        )
        return x
```
