[meta]
version = "1.0"
default_language = "cuda"

# -------------------------------------------------------------------------
# Shared Templates: Used by all languages with placeholders
# -------------------------------------------------------------------------
[shared]
problem_statement = """
You write custom {language_display} to replace the pytorch operators in the given architecture to get speedups.

You have complete freedom to choose the set of operators you want to replace. You may make the decision to replace some operators with custom {language_display} and leave others unchanged. You may replace multiple operators with custom implementations, consider operator fusion opportunities (combining multiple operators into a single kernel, for example, combining matmul+relu), or algorithmic changes (such as online softmax). You are only limited by your imagination.
"""

instruction = """
Optimize the architecture named Model with custom {language_display}! Name your optimized output architecture ModelNew. Output the new code in codeblocks. Please generate real code, NOT pseudocode, make sure the code compiles and is fully functional. Just output the new model code, no other text, and NO testing code!
"""

# Shared example architecture (same for all languages)
few_shot_example_arch = "src/prompts/model_ex_add.py"

# -------------------------------------------------------------------------
# Languages: Language-specific configuration (minimal, just what varies)
# -------------------------------------------------------------------------
[languages.triton]
language_display = "Triton kernels"
few_shot_new_arch = "src/prompts/model_new_ex_add_triton.py"

[languages.cuda]
language_display = "CUDA operators"
few_shot_new_arch = "src/prompts/model_new_ex_add.py"

[languages.cute]
language_display = "CuTe (CUTLASS) kernels"
few_shot_new_arch = "src/prompts/model_new_ex_add_cute.py"

# -------------------------------------------------------------------------
# Options: Different prompt construction modes
# -------------------------------------------------------------------------
[options.basic]
# Basic prompt: problem statement + architecture + instruction
description = "Minimal prompt with just problem statement and architecture"
components = ["problem_statement", "arch_block", "instruction"]

[options.few_shot]
# With few-shot examples
description = "Includes few-shot examples to demonstrate the task"
components = ["problem_statement", "few_shot_block", "arch_block", "instruction"]
requires_example = true

[options.hardware_info]
# Hardware-aware prompt
description = "Includes GPU hardware specifications and best practices"
components = ["problem_statement", "few_shot_block", "hardware_header", "hardware_specs", "hardware_definitions", "hardware_best_practices", "arch_block", "instruction"]
requires_gpu = true
requires_example = true

[options.fix_compile]
# For fixing compilation errors
description = "Prompt for fixing compilation errors"
components = ["problem_statement", "arch_with_context", "failed_kernel", "compile_metadata", "fix_footer"]

[options.fix_correctness]
# For fixing correctness errors
description = "Prompt for fixing correctness errors"
components = ["problem_statement", "arch_with_context", "failed_kernel", "correctness_metadata", "fix_footer"]

# -------------------------------------------------------------------------
# Templates: Reusable text blocks with placeholders
# -------------------------------------------------------------------------
[templates.common]

# --- Architecture Presentation ---
# Used in prompts to present the reference architecture that needs optimization
arch_block = """
You are given the following architecture:


{ref_arch_src}

"""

# Used in fix prompts to reference the architecture with contextual phrasing
arch_with_context = """
With the following architecture:


{ref_arch_src}

"""

# --- Few-Shot Learning ---
# Shows an example of input architecture and its optimized version
few_shot_block = """
Here's an example to show you the syntax of inline embedding custom {language_display} in torch: The example given architecture is:

{example_arch_src}


The example new arch with custom {language_display} looks like this:


{example_new_arch_src}

"""

# --- Error Fix Templates ---
# Presents a kernel that failed (used in fix_compile and fix_correctness options)
failed_kernel = """
You generated the following solution and it failed {failure_type}:


{custom_kernel}

"""

compile_metadata = """
Here's the metadata of the compilation error:


{metadata}

"""

correctness_metadata = """
Here's the metadata of the correctness error:


{metadata}

"""

fix_footer = """
Please fix the {failure_type} in the new model code. Please output the corrected code in codeblocks.
"""

# -------------------------------------------------------------------------
# Hardware Templates: GPU-specific information blocks
# -------------------------------------------------------------------------
[templates.hardware]
hardware_header = """
Here is some information about the underlying hardware that you should keep in mind.
"""

hardware_specs = """
The GPU that will run the kernel is NVIDIA {gpu_name}, {gpu_architecture} architecture.

{gpu_specs_bullets}
"""

hardware_definitions = """
Here are some concepts about the GPU architecture that could be helpful:

{gpu_definitions_bullets}
"""

hardware_best_practices = """
Here are some best practices for writing kernels on GPU:

{gpu_best_practices_bullets}
"""
