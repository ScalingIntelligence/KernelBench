{
  "correct": false,
  "grid": 64,
  "block": 256,
  "llm_out": "```ptx\n.version 7.0\n.target sm_52\n.address_size 64\n\n.visible .entry my_kernel(\n    .param .u64 my_kernel_param_0,    // input pointer\n    .param .u64 my_kernel_param_1     // output pointer\n)\n{\n    .shared .align 4 .f32 sdata[516];\n\n    .reg .pred  %p<6>;\n    .reg .b32   %r<50>;\n    .reg .b64   %rd<20>;\n    .reg .f32   %f<40>;\n\n    // Load parameters\n    ld.param.u64 %rd1, [my_kernel_param_0];\n    ld.param.u64 %rd2, [my_kernel_param_1];\n\n    // Thread and block indices\n    mov.u32 %r1, %tid.x;     // tid\n    mov.u32 %r2, %ctaid.x;   // channel index (block id)\n\n    // Constants\n    mov.u32 %r3, 29360128;   // elements per channel (112*512*512)\n    mov.u32 %r4, 256;        // stride (threads per block)\n\n    // Initialize accumulators\n    mov.f32 %f1, 0.0;        // sum\n    mov.f32 %f2, 0.0;        // sumsq\n\n    // off = tid\n    mov.u32 %r5, %r1;\n\nLOOP1:\n    setp.ge.u32 %p1, %r5, %r3;\n    @%p1 bra LOOP1_END;\n\n    // Compute w,h,n from linear index\n    and.b32 %r6, %r5, 511;        // w\n    shr.u32 %r7, %r5, 9;          // tmp = idx >> 9\n    and.b32 %r8, %r7, 511;        // h\n    shr.u32 %r9, %r7, 9;          // n\n\n    // idx = ((((n*64)+c)*512 + h)*512 + w)\n    mul.lo.u32 %r10, %r9, 64;\n    add.u32    %r10, %r10, %r2;\n    mul.lo.u32 %r10, %r10, 512;\n    add.u32    %r10, %r10, %r8;\n    mul.lo.u32 %r10, %r10, 512;\n    add.u32    %r10, %r10, %r6;\n\n    // byte offset\n    mul.wide.u32 %rd3, %r10, 4;\n    add.u64 %rd4, %rd1, %rd3;\n\n    ld.global.f32 %f3, [%rd4];\n\n    // accumulate\n    add.f32 %f1, %f1, %f3;\n    mul.f32 %f4, %f3, %f3;\n    add.f32 %f2, %f2, %f4;\n\n    // increment\n    add.u32 %r5, %r5, %r4;\n    bra LOOP1;\n\nLOOP1_END:\n\n    // base shared address\n    mov.u32 %r20, sdata;\n\n    // store sum\n    mul.lo.u32 %r21, %r1, 4;\n    add.u32 %r22, %r20, %r21;\n    st.shared.f32 [%r22], %f1;\n\n    // store sumsq\n    add.u32 %r23, %r1, 256;\n    mul.lo.u32 %r23, %r23, 4;\n    add.u32 %r23, %r20, %r23;\n    st.shared.f32 [%r23], %f2;\n\n    // Synchronize threads\n    bar.sync 0;\n\n    // Reduction by thread 0\n    setp.ne.u32 %p2, %r1, 0;\n    @%p2 bra AFTER_REDUCE;\n\n    mov.f32 %f5, 0.0;     // total sum\n    mov.f32 %f6, 0.0;     // total sumsq\n    mov.u32 %r24, 0;\n\nRED_LOOP:\n    setp.ge.u32 %p3, %r24, 256;\n    @%p3 bra RED_LOOP_END;\n\n    // load partial sum\n    mul.lo.u32 %r25, %r24, 4;\n    add.u32    %r26, %r20, %r25;\n    ld.shared.f32 %f7, [%r26];\n    add.f32 %f5, %f5, %f7;\n\n    // load partial sumsq\n    add.u32 %r27, %r24, 256;\n    mul.lo.u32 %r27, %r27, 4;\n    add.u32    %r27, %r20, %r27;\n    ld.shared.f32 %f8, [%r27];\n    add.f32 %f6, %f6, %f8;\n\n    add.u32 %r24, %r24, 1;\n    bra RED_LOOP;\n\nRED_LOOP_END:\n    // mean and variance\n    cvt.rn.f32.u32 %f9, %r3;     // N as float\n    div.rn.f32 %f10, %f5, %f9;   // mean\n    div.rn.f32 %f11, %f6, %f9;   // E[x^2]\n    mul.f32 %f12, %f10, %f10;    // mean^2\n    sub.f32 %f13, %f11, %f12;    // variance\n    mov.f32 %f14, 1.0e-5;\n    add.f32 %f13, %f13, %f14;    // variance + eps\n    rsqrt.approx.f32 %f15, %f13; // inv_std\n\n    // store mean and inv_std to shared memory\n    mul.lo.u32 %r28, 512, 4;\n    add.u32 %r28, %r20, %r28;\n    st.shared.f32 [%r28], %f10;  // mean\n\n    mul.lo.u32 %r29, 513, 4;\n    add.u32 %r29, %r20, %r29;\n    st.shared.f32 [%r29], %f15;  // inv_std\n\nAFTER_REDUCE:\n    bar.sync 0;\n\n    // load mean and inv_std\n    mul.lo.u32 %r30, 512, 4;\n    add.u32 %r30, %r20, %r30;\n    ld.shared.f32 %f16, [%r30];\n\n    mul.lo.u32 %r31, 513, 4;\n    add.u32 %r31, %r20, %r31;\n    ld.shared.f32 %f17, [%r31];\n\n    // second pass\n    mov.u32 %r32, %r1; // offset\n\nLOOP2:\n    setp.ge.u32 %p4, %r32, %r3;\n    @%p4 bra LOOP2_END;\n\n    // compute w,h,n\n    and.b32 %r6, %r32, 511;\n    shr.u32 %r7, %r32, 9;\n    and.b32 %r8, %r7, 511;\n    shr.u32 %r9, %r7, 9;\n\n    mul.lo.u32 %r10, %r9, 64;\n    add.u32    %r10, %r10, %r2;\n    mul.lo.u32 %r10, %r10, 512;\n    add.u32    %r10, %r10, %r8;\n    mul.lo.u32 %r10, %r10, 512;\n    add.u32    %r10, %r10, %r6;\n\n    mul.wide.u32 %rd5, %r10, 4;\n\n    add.u64 %rd6, %rd1, %rd5;\n    ld.global.f32 %f18, [%rd6];\n\n    // normalize\n    sub.f32 %f18, %f18, %f16;\n    mul.f32 %f18, %f18, %f17;\n\n    add.u64 %rd7, %rd2, %rd5;\n    st.global.f32 [%rd7], %f18;\n\n    // next\n    add.u32 %r32, %r32, %r4;\n    bra LOOP2;\n\nLOOP2_END:\n    ret;\n}\n```\n\nLAUNCH = (64, 256)"
}